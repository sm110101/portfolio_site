<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Supervised Learning – Sean Morris</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/sm_logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/sm_logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sean Morris</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../report/report.html"> 
<span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-technical-details" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Technical details</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-technical-details">    
        <li>
    <a class="dropdown-item" href="../../technical-details/data-collection/main.html">
 <span class="dropdown-text">Data-collection</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/data-cleaning/main.html">
 <span class="dropdown-text">Data-cleaning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/eda/main.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/unsupervised-learning/main.html">
 <span class="dropdown-text">Unsupervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/supervised-learning/main.html">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/progress-log.html">
 <span class="dropdown-text">Progress Log</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/llm-usage-log.html">
 <span class="dropdown-text">LLM usage Log</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/spm122/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/sm110101"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sm110101"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/sean.morriss/"> <i class="bi bi-instagram" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#section-1-setup" id="toc-section-1-setup" class="nav-link" data-scroll-target="#section-1-setup">Section 1: Setup</a>
  <ul class="collapse">
  <li><a href="#importing-data-and-packages" id="toc-importing-data-and-packages" class="nav-link" data-scroll-target="#importing-data-and-packages">Importing Data and Packages</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">Data Preprocessing</a>
  <ul class="collapse">
  <li><a href="#handling-zero-vote-rows" id="toc-handling-zero-vote-rows" class="nav-link" data-scroll-target="#handling-zero-vote-rows">Handling Zero-Vote rows</a></li>
  <li><a href="#encoding-verified-column" id="toc-encoding-verified-column" class="nav-link" data-scroll-target="#encoding-verified-column">Encoding <code>verified</code> Column</a></li>
  <li><a href="#encoding-productid" id="toc-encoding-productid" class="nav-link" data-scroll-target="#encoding-productid">Encoding <code>productID</code></a></li>
  <li><a href="#encoding-binary-target" id="toc-encoding-binary-target" class="nav-link" data-scroll-target="#encoding-binary-target">Encoding Binary Target</a></li>
  <li><a href="#dropping-unnecessary-columns" id="toc-dropping-unnecessary-columns" class="nav-link" data-scroll-target="#dropping-unnecessary-columns">Dropping Unnecessary Columns</a></li>
  <li><a href="#renaming-and-reordering-columns-for-cleanliness" id="toc-renaming-and-reordering-columns-for-cleanliness" class="nav-link" data-scroll-target="#renaming-and-reordering-columns-for-cleanliness">Renaming and Reordering Columns for Cleanliness</a></li>
  </ul></li>
  <li><a href="#feature-extraction" id="toc-feature-extraction" class="nav-link" data-scroll-target="#feature-extraction">Feature Extraction</a>
  <ul class="collapse">
  <li><a href="#polarity" id="toc-polarity" class="nav-link" data-scroll-target="#polarity">Polarity</a></li>
  <li><a href="#tf-idf" id="toc-tf-idf" class="nav-link" data-scroll-target="#tf-idf">TF-IDF</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-2-classification" id="toc-section-2-classification" class="nav-link" data-scroll-target="#section-2-classification">Section 2: Classification</a>
  <ul class="collapse">
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection">Model Selection</a>
  <ul class="collapse">
  <li><a href="#binary-classification" id="toc-binary-classification" class="nav-link" data-scroll-target="#binary-classification">Binary Classification</a></li>
  <li><a href="#multi-class-classification" id="toc-multi-class-classification" class="nav-link" data-scroll-target="#multi-class-classification">Multi-class Classification</a></li>
  </ul></li>
  <li><a href="#classification-model-pipeline" id="toc-classification-model-pipeline" class="nav-link" data-scroll-target="#classification-model-pipeline">Classification Model Pipeline</a></li>
  <li><a href="#binary-classification-1" id="toc-binary-classification-1" class="nav-link" data-scroll-target="#binary-classification-1">Binary Classification</a>
  <ul class="collapse">
  <li><a href="#tf-idf-features-only" id="toc-tf-idf-features-only" class="nav-link" data-scroll-target="#tf-idf-features-only">TF-IDF Features Only</a></li>
  <li><a href="#non-tf-idf-features" id="toc-non-tf-idf-features" class="nav-link" data-scroll-target="#non-tf-idf-features">Non TF-IDF Features</a></li>
  <li><a href="#all-features" id="toc-all-features" class="nav-link" data-scroll-target="#all-features">All Features</a></li>
  </ul></li>
  <li><a href="#multi-class-prediction" id="toc-multi-class-prediction" class="nav-link" data-scroll-target="#multi-class-prediction">Multi-Class Prediction</a>
  <ul class="collapse">
  <li><a href="#tf-idf-features-only-1" id="toc-tf-idf-features-only-1" class="nav-link" data-scroll-target="#tf-idf-features-only-1">TF-IDF Features Only</a></li>
  <li><a href="#non-tf-idf-features-1" id="toc-non-tf-idf-features-1" class="nav-link" data-scroll-target="#non-tf-idf-features-1">Non TF-IDF Features</a></li>
  <li><a href="#all-features-1" id="toc-all-features-1" class="nav-link" data-scroll-target="#all-features-1">All Features</a></li>
  </ul></li>
  <li><a href="#multi-class-prediction-with-undersampling" id="toc-multi-class-prediction-with-undersampling" class="nav-link" data-scroll-target="#multi-class-prediction-with-undersampling">Multi-Class Prediction with Undersampling</a>
  <ul class="collapse">
  <li><a href="#all-features-unsampled" id="toc-all-features-unsampled" class="nav-link" data-scroll-target="#all-features-unsampled">All Features, Unsampled</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#section-3-regression" id="toc-section-3-regression" class="nav-link" data-scroll-target="#section-3-regression">Section 3: Regression</a>
  <ul class="collapse">
  <li><a href="#model-selection-1" id="toc-model-selection-1" class="nav-link" data-scroll-target="#model-selection-1">Model Selection</a>
  <ul class="collapse">
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#classification" id="toc-classification" class="nav-link" data-scroll-target="#classification">Classification</a>
  <ul class="collapse">
  <li><a href="#binary-classification-2" id="toc-binary-classification-2" class="nav-link" data-scroll-target="#binary-classification-2">Binary Classification</a></li>
  <li><a href="#multi-class-classification-1" id="toc-multi-class-classification-1" class="nav-link" data-scroll-target="#multi-class-classification-1">Multi-class Classification</a></li>
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges">Challenges</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Supervised Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><br> <br></p>
<section id="overview" class="level1">
<h1>Overview</h1>
<p>In this section, I leverage several different supervised machine learning techniques to run predictions on three different target variables. As a refresher, supervised machine learning is a suite of algorithms that are trained labeled datasets to classify or predict outcomes for specific target variables<span class="citation" data-cites="IBMsupervised"><sup><a href="#ref-IBMsupervised" role="doc-biblioref">1</a></sup></span>. In this section, I use three subcategories of supervised learning methods, including regression, binary classification, and multi-class classification. For training, I take advantage of <code>scikit-learn</code>’s train_test_split object to break up my data into a training and testing set. After running each model, I will look at each model’s respective error metrics to gauge their performance in prediction/classification tasks.</p>
<p>Before beginning the modeling process, I carry out feature extraction on our text data. For this, I leverage the TF-IDF embedding method that has been used in multiple parts of this study. From there, I build out two custom modeling pipelines for classification and regression models. The piplines will be modular, allowing us to control which feature are used in the modeling process. Each of the pipelines will apply a set of specific methods for their given goal, compare each result and output the highest performing model’s metrics.</p>
<p>At the end of this section I will present my findings, including a summary of each model’s performance, and some visualizations to supplement said fidings.</p>
</section>
<section id="section-1-setup" class="level1">
<h1>Section 1: Setup</h1>
<p><strong>Importing Data and Packages</strong></p>
<p><strong>Data Preprocessing</strong></p>
<p><strong>Feature Extraction</strong></p>
<section id="importing-data-and-packages" class="level2">
<h2 class="anchored" data-anchor-id="importing-data-and-packages">Importing Data and Packages</h2>
<p>Let’s begin our process by importing relevant packages</p>
<div id="cell-4" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loading and manipulation packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gzip</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Data preprocessing and feature extraction packages</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, MinMaxScaler, LabelEncoder</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> textblob <span class="im">import</span> TextBlob</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Model training packages</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression, Ridge</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Model evaluation packages</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    accuracy_score,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    precision_score,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    recall_score,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    f1_score,</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    roc_auc_score,</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    confusion_matrix,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    mean_squared_error,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    mean_absolute_error,</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    r2_score,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    roc_curve,</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    auc</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization packages</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Ignoring warnings </span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we can load in our data:</p>
<div id="cell-6" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pathway to raw data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data_path <span class="op">=</span> <span class="st">"../../data/processed-data/reviews_short.csv.gz"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Unzip the CSV file</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(data_path, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read the CSV file into a dataframe</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    reviews <span class="op">=</span> pd.read_csv(f)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>reviews.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">reviewRating</th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">reviewTime</th>
<th data-quarto-table-cell-role="th">reviewerID</th>
<th data-quarto-table-cell-role="th">productID</th>
<th data-quarto-table-cell-role="th">reviewerName</th>
<th data-quarto-table-cell-role="th">reviewText</th>
<th data-quarto-table-cell-role="th">summary</th>
<th data-quarto-table-cell-role="th">reviewTextClean</th>
<th data-quarto-table-cell-role="th">summaryClean</th>
<th data-quarto-table-cell-role="th">binary_target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.0</td>
<td>2</td>
<td>False</td>
<td>2016-06-17</td>
<td>A7HY1CEDK0204</td>
<td>B00I9GYG8O</td>
<td>Jor El</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>positive</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h2>
<section id="handling-zero-vote-rows" class="level3">
<h3 class="anchored" data-anchor-id="handling-zero-vote-rows">Handling Zero-Vote rows</h3>
<p>To start out this process, I shift my focus to the heavily-skewed ‘vote’ column, where a vast majority of rows have zero votes. In order to reconcile this, while making the <code>vote</code> column still usable in our models, I will convert it into a binary-encoded column called <code>vote_binary</code> where its values are <span class="math inline">\(1\)</span> if the value for <code>vote</code> is non-zero, and <span class="math inline">\(0\)</span> otherwise</p>
<div id="cell-9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking % of zero-vote rows</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Percent of reviews with 0 votes: </span><span class="sc">{</span><span class="bu">round</span>((<span class="bu">len</span>(reviews.loc[reviews[<span class="st">'vote'</span>] <span class="op">==</span> <span class="dv">0</span>])<span class="op">/</span><span class="bu">len</span>(reviews)<span class="op">*</span><span class="dv">100</span>), <span class="dv">2</span>)<span class="sc">}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Percent of reviews with 0 votes: 86.02%</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating vote_binary column</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>reviews[<span class="st">'vote_binary'</span>] <span class="op">=</span> (reviews[<span class="st">'vote'</span>] <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing result</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>reviews[[<span class="st">'vote'</span>, <span class="st">'vote_binary'</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">vote_binary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="encoding-verified-column" class="level3">
<h3 class="anchored" data-anchor-id="encoding-verified-column">Encoding <code>verified</code> Column</h3>
<p>Next, let’s do the same thing for <code>verified</code>, setting “True” to 1, and “False” to 0.</p>
<div id="cell-12" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating verified_binary column</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>reviews[<span class="st">'verified_binary'</span>] <span class="op">=</span> (reviews[<span class="st">'verified'</span>] <span class="op">==</span> <span class="va">True</span>).astype(<span class="bu">int</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing result</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>reviews[[<span class="st">'verified'</span>, <span class="st">'verified_binary'</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">verified_binary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>False</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>False</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>True</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>True</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="encoding-productid" class="level3">
<h3 class="anchored" data-anchor-id="encoding-productid">Encoding <code>productID</code></h3>
<p>Here, I use sklearn’s <a href="https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html"><code>LabelEncoder</code></a> object to convert the productID column into a more useful format for modeling. For this process, I will keep both the non-encoded and encoded version of <code>productID</code>, as the non-encoded version may be useful for tree-based algorithms like Random Forests and Gradient Boosting, while the encoded version may prove more useful in models that require a numerical input, like Logistic Regression and Support Vector Machines SVM.</p>
<div id="cell-14" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initializing LabelEncoder object</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting to our productID column</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>reviews[<span class="st">'productID_encoded'</span>] <span class="op">=</span> encoder.fit_transform(reviews[<span class="st">'productID'</span>])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking result</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>reviews[[<span class="st">'productID'</span>, <span class="st">'productID_encoded'</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">productID</th>
<th data-quarto-table-cell-role="th">productID_encoded</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>B00I9GYG8O</td>
<td>27766</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>B01DB6BK5I</td>
<td>42622</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>B00011KM3I</td>
<td>1415</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>B000EDOSFQ</td>
<td>3153</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>B01CVOLKKQ</td>
<td>42382</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="encoding-binary-target" class="level3">
<h3 class="anchored" data-anchor-id="encoding-binary-target">Encoding Binary Target</h3>
<p>Here, I use binary encoding to create a new <code>binary_sentiment</code> column that adjusts values in the <code>binary_target</code> column. Specifically, I will change the value “positive” to 1, and “negative” to 0.</p>
<div id="cell-16" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating verified_binary column</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>reviews[<span class="st">'binary_sentiment'</span>] <span class="op">=</span> (reviews[<span class="st">'binary_target'</span>] <span class="op">==</span> <span class="st">"positive"</span>).astype(<span class="bu">int</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing result</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>reviews[[<span class="st">'binary_target'</span>, <span class="st">'binary_sentiment'</span>]].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">binary_target</th>
<th data-quarto-table-cell-role="th">binary_sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>positive</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>negative</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>positive</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>positive</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>negative</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="dropping-unnecessary-columns" class="level3">
<h3 class="anchored" data-anchor-id="dropping-unnecessary-columns">Dropping Unnecessary Columns</h3>
<p>With that out of the way, let’s begin to drop unnecessary columns. For this section, we will drop:</p>
<ul>
<li><code>binary_sentiment:</code> String-encoded sentiment column</li>
<li><code>vote:</code> Non-encoded vote column</li>
<li><code>productID:</code> Non-encoded product ID</li>
<li><code>verified:</code> Non-encoded values for varified column</li>
<li><code>reviewTime:</code> Time of review, since we are not conducting any time series analysis here</li>
<li><code>reviewerID:</code> ID of reviewer</li>
<li><code>reviewerName:</code> Name of reviewer</li>
</ul>
<p>I choose to leave in the uncleaned versions of the review text and summary in case I want to use some all-in-one embedding tools down the line like <code>BERT</code>.</p>
<div id="cell-18" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting columns to drop </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>cols_to_drop <span class="op">=</span> [<span class="st">'binary_target'</span>, <span class="st">'verified'</span>, <span class="st">'vote'</span>,<span class="st">'productID'</span>, <span class="st">'reviewTime'</span>, <span class="st">'reviewerID'</span>, <span class="st">'reviewerName'</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropping</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>reviews <span class="op">=</span> reviews.drop(columns<span class="op">=</span>cols_to_drop)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing result</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>reviews.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">reviewRating</th>
<th data-quarto-table-cell-role="th">reviewText</th>
<th data-quarto-table-cell-role="th">summary</th>
<th data-quarto-table-cell-role="th">reviewTextClean</th>
<th data-quarto-table-cell-role="th">summaryClean</th>
<th data-quarto-table-cell-role="th">vote_binary</th>
<th data-quarto-table-cell-role="th">verified_binary</th>
<th data-quarto-table-cell-role="th">productID_encoded</th>
<th data-quarto-table-cell-role="th">binary_sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>1</td>
<td>0</td>
<td>27766</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="renaming-and-reordering-columns-for-cleanliness" class="level3">
<h3 class="anchored" data-anchor-id="renaming-and-reordering-columns-for-cleanliness">Renaming and Reordering Columns for Cleanliness</h3>
<div id="cell-20" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Renaming columns </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>renamed_columns <span class="op">=</span> {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reviewRating'</span>: <span class="st">'rating'</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reviewText'</span>: <span class="st">'text'</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'summary'</span>: <span class="st">'summary'</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reviewTextClean'</span>: <span class="st">'text_clean'</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'summaryClean'</span>: <span class="st">'summary_clean'</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'binary_sentiment'</span>: <span class="st">'sentiment'</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vote_binary'</span>: <span class="st">'vote'</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'verified_binary'</span>: <span class="st">'verified'</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'productID_encoded'</span>: <span class="st">'product_id'</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>reviews <span class="op">=</span> reviews.rename(columns<span class="op">=</span>renamed_columns)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Rordering columns for clarity</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>column_order <span class="op">=</span> [</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'product_id'</span>,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'rating'</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vote'</span>,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'verified'</span>,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sentiment'</span>,</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'text_clean'</span>, </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'summary_clean'</span>, </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'text'</span>, </span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'summary'</span>, </span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>reviews <span class="op">=</span> reviews[column_order]</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing result</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>reviews.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">product_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">sentiment</th>
<th data-quarto-table-cell-role="th">text_clean</th>
<th data-quarto-table-cell-role="th">summary_clean</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">summary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>27766</td>
<td>5</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>As a reminder for our boolean columns:</p>
<ul>
<li><code>vote</code>: <span class="math inline">\((1 \ \text{for non-zero vote counts}, \ 0 \  \text{otherwise})\)</span></li>
<li><code>verified</code>: <span class="math inline">\((1 \ \text{if account is verified}, \ 0 \  \text{otherwise})\)</span></li>
<li><code>sentiment</code>: <span class="math inline">\((1 \ \text{if rating} \ \geq{4}, \ 0 \  \text{if rating} \ &lt; 4)\)</span></li>
</ul>
</section>
</section>
<section id="feature-extraction" class="level2">
<h2 class="anchored" data-anchor-id="feature-extraction">Feature Extraction</h2>
<section id="polarity" class="level3">
<h3 class="anchored" data-anchor-id="polarity">Polarity</h3>
<p>Before moving on to more advanced feature extraction, I am going to quickly add back the <code>polarity</code> column that we worked with in the EDA section to serve as a target variable in our regression models. If you need a refresher on polarity, please head over to the <a href="../../technical-details/eda/main.html">EDA</a> section where I provide an overview.</p>
<div id="cell-23" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TextBlob allows us to feed raw text into it for polarity extraction, so I will do that here</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>reviews[<span class="st">'polarity'</span>] <span class="op">=</span> reviews[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: TextBlob(x).sentiment.polarity)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># printing result</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>reviews[[<span class="st">'text'</span>, <span class="st">'rating'</span>, <span class="st">'polarity'</span>]].head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">polarity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>5</td>
<td>0.321675</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="tf-idf" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf">TF-IDF</h3>
<p>Term frequency-inverse document freqeuncy (TF-IDF) is a process that measures the importance of a word (or pair of words in our case) by comparing its rate of appearance in a document to its rate of appearance in a whole collection of documents. In this approach, the weight of a given word or word-pair depends both on its frequency and rarity. The benefit of TF-IDF over a simple document term matrix is that TF-IDF will punish words/pairs that occur frequently across our corpus, and favor words that have importance in their respective documents, and are found less frequently across the corpus<span class="citation" data-cites="TFIDF"><sup><a href="#ref-TFIDF" role="doc-biblioref">2</a></sup></span>. Recall the formulaic representation of TF-IDF that I include on the home page:</p>
<p>In equation form<span class="citation" data-cites="TFIDF"><sup><a href="#ref-TFIDF" role="doc-biblioref">2</a></sup></span>: <span class="math display">\[
\text{TF}(t,d) = \frac{\text{Number of times term t appears in document d}}{\text{Total number of terms in document d}}
\]</span> <span class="math display">\[
\text{IDF}(t,D) = log_{e}\frac{\text{Total number of documents D in corpus}}{\text{Number of documents containing term t}}
\]</span> <span class="math display">\[
\text{TF-IDF} = TF(t,d) \cdot IDF(t,D)
\]</span></p>
<p>For its implementation here, I define the function <code>tfidf_embedding()</code> that takes in our pandas dataframe, applies TF-IDF to the cleaned review text column, and returns a dataframe that contains all of the tfidf features. The main function process uses the <code>TfidfVectorizer</code> from the sklearn library. In my implementation, I feed in the following parameters<span class="citation" data-cites="scikitTFIDF"><sup><a href="#ref-scikitTFIDF" role="doc-biblioref">3</a></sup></span>:</p>
<ul>
<li><code>max_features</code>: Threshold for the number of features to be ranked by their term frequency across the corpus.</li>
<li><code>ngram_range</code>: A tuple that controls the range of n-values for different n-grams to be extracted. In my case, I use (1,2) to include both unigrams and bigrams.</li>
</ul>
<div id="cell-25" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tfidf_embedding(df, text_column, max_features<span class="op">=</span><span class="dv">1000</span>, ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>)):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This function:</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1) Takes in a pandas dataframe and target text column</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">    2) Applies TF-IDF embedding using the set parameters</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">    3) Returns pandas dataframe with tf-idf features </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize TfidfVectorizer</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    tfidf <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span>max_features, ngram_range<span class="op">=</span>ngram_range, stop_words<span class="op">=</span><span class="st">'english'</span>) <span class="co"># Included stopwords param here to help clean up spots that I may have missed in text processing section</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit tfidf to our target column</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    tfidf_features <span class="op">=</span> tfidf.fit_transform(df[text_column])</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create pandas dataframe for tfidf features</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    tfidf_df <span class="op">=</span> pd.DataFrame(tfidf_features.toarray(), columns<span class="op">=</span>[<span class="ss">f"tfidf_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(tfidf_features.shape[<span class="dv">1</span>])])</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenate TF-IDF features df with our original df to maintain other features</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    df_tfidf <span class="op">=</span> pd.concat([df.reset_index(drop<span class="op">=</span><span class="va">True</span>), tfidf_df.reset_index(drop<span class="op">=</span><span class="va">True</span>)], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_tfidf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-26" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Applying this function to our reviews data set</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>reviews_tfidf <span class="op">=</span> tfidf_embedding(reviews, text_column<span class="op">=</span><span class="st">'text_clean'</span>, max_features<span class="op">=</span><span class="dv">500</span>, ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing shape</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>reviews_tfidf.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(100000, 510)</code></pre>
</div>
</div>
<div id="cell-27" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>reviews_tfidf.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">product_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">sentiment</th>
<th data-quarto-table-cell-role="th">text_clean</th>
<th data-quarto-table-cell-role="th">summary_clean</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">summary</th>
<th data-quarto-table-cell-role="th">polarity</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">tfidf_490</th>
<th data-quarto-table-cell-role="th">tfidf_491</th>
<th data-quarto-table-cell-role="th">tfidf_492</th>
<th data-quarto-table-cell-role="th">tfidf_493</th>
<th data-quarto-table-cell-role="th">tfidf_494</th>
<th data-quarto-table-cell-role="th">tfidf_495</th>
<th data-quarto-table-cell-role="th">tfidf_496</th>
<th data-quarto-table-cell-role="th">tfidf_497</th>
<th data-quarto-table-cell-role="th">tfidf_498</th>
<th data-quarto-table-cell-role="th">tfidf_499</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>27766</td>
<td>5</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
<td>0.321675</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.219799</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>1 rows × 510 columns</p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="section-2-classification" class="level1">
<h1>Section 2: Classification</h1>
<p><strong>Model Selection</strong></p>
<p><strong>Modeling Pipline</strong></p>
<p><strong>Binary Classification</strong></p>
<p><strong>Multi-class Classification</strong></p>
<p><strong>Undersampling</strong></p>
<section id="model-selection" class="level2">
<h2 class="anchored" data-anchor-id="model-selection">Model Selection</h2>
<section id="binary-classification" class="level3">
<h3 class="anchored" data-anchor-id="binary-classification">Binary Classification</h3>
<p><strong><em>Predicting sentiment value (positive or negative)</em></strong></p>
<section id="logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
<p>Logistic regression is a type of supervised learning technique that is often used to predict a binary outcome (A or B). The model does this by taking in a set of independent variables for a given observation, and calculating the probability that they belong to a certain target class. Logistic regressions use a <a href="https://www.linkedin.com/pulse/understanding-sigmoid-function-logistic-regression-piduguralla/">sigmoid function</a> that maps the linear combination of inputs to a final probability in the range [0, 1].<span class="citation" data-cites="sigmoid"><sup><a href="#ref-sigmoid" role="doc-biblioref">4</a></sup></span> If the value returned by the sigmoid function is <span class="math inline">\(\geq 0.5\)</span>, then the model assigns the observation to the target class (in our case it assigns the value <span class="math inline">\(1\)</span> to reviews that it believes are positive)</p>
<p><strong>Sigmoid Function:</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/sigmoid.png" class="img-fluid" width="500"> <br> Source: <a href="https://www.dailydoseofds.com/why-do-we-use-sigmoid-in-logistic-regression/">Daily Dose of Data Science</a> <br></p>
<ul>
<li><strong>Model Rationale</strong></li>
</ul>
<p>When selecting which binary classification models I wanted to use for predicting <code>sentiment</code>, logistic regression stood out as an obvious baseline. The model’s simplicity, and direct probabilistic output makes it a reliable and lightweight option for running predictions using TF-IDF embeddings.</p>
</section>
<section id="random-forest" class="level4">
<h4 class="anchored" data-anchor-id="random-forest">Random Forest</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
<p>Random forests are a <a href="https://en.wikipedia.org/wiki/Decision_tree">decision tree</a> based approach to machine learning. Decision trees are non-parametric models that can be used for both regression and classification. Their process begins by selecting a “root node”, or initial question about a feature in the data. From there they break off into different branches that ask more and more specific questions about the features. The end result, also called the “leaf node,” outputs the class that best fits the criteria defined in the upper nodes.<span class="citation" data-cites="decisiontrees"><sup><a href="#ref-decisiontrees" role="doc-biblioref">5</a></sup></span> Random forest models take this same approach, but instead of relying on a single tree, they build multiple decision trees during the training process, and aggregate their results to provide stronger prediction.</p>
<p><strong>Decision Tree vs.&nbsp;Random Forest:</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/trees_v_forests.jpg" class="img-fluid" width="500"> <br> Source: <a href="https://towardsdatascience.com/10-decision-trees-are-better-than-1-719406680564">Towards Data Science</a> <br></p>
<ul>
<li><strong>Model Rationale</strong></li>
</ul>
<p>When brainstorming which models I wanted to use for binary classification, Random Forests stood out as a solid candidate for their ability to handle high dimensional data (like we see with our TF-IDF embeddings). Random Forests also come with the added benefit of being robust to potentially overfitting the data - as their ensemble structure requires different individual trees to be trained on subsets of the data.</p>
</section>
</section>
<section id="multi-class-classification" class="level3">
<h3 class="anchored" data-anchor-id="multi-class-classification">Multi-class Classification</h3>
<p><strong><em>Predicting review rating (1-5)</em></strong></p>
<section id="support-vector-machine-svm" class="level4">
<h4 class="anchored" data-anchor-id="support-vector-machine-svm">Support Vector Machine (SVM)</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
<p>Support Vector Machines (SVMs) are supervised learning techniques that are commonly applied to classification problems. They assign classes by finding the optimal “hyperplane” in a high dimensional space that maximizes the distance between groups of data points.<span class="citation" data-cites="SVM"><sup><a href="#ref-SVM" role="doc-biblioref">6</a></sup></span> In simple english, SVMs are looking for the best line of boundary that creates the largest distance between groups of points, and then assigns the different groups to their own class.</p>
<p><strong>SVM Overview:</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/svm.png" class="img-fluid" width="400"> <br> Source: <a href="https://medium.com/analytics-vidhya/support-vector-machine-svm-i-can-do-both-classification-and-regression-c90235e847df">Medium</a> <br></p>
<ul>
<li><strong>Model Rationale</strong></li>
</ul>
<p>For the task of classifying different review scores, I consider the use of SVM because it excels in separating points in high-dimensions. In the case of my my 500 dimensional TF-IDF feature space, SVM should be able to successfully separate groups of points into our desired ratings scores.</p>
</section>
<section id="multinomial-naive-bayes" class="level4">
<h4 class="anchored" data-anchor-id="multinomial-naive-bayes">Multinomial Naive Bayes</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
<p>Multinomial Naive Bayes (MNB) takes a probabilistic approach to assigning different classes by first calculating the probabilities of different classes based on their frequency in the data. It assumes that all features are “conditionally independent” - meaning it treats each feature as being distinct and unrelated to the others.<span class="citation" data-cites="MNB"><sup><a href="#ref-MNB" role="doc-biblioref">7</a></sup></span> This assumption makes the model highly computationally efficient, as it only has to assign a single probability to each feature.</p>
<ul>
<li><strong>Model Rationale</strong></li>
</ul>
<p>For predicting the different review scores in my data set, I elect to use MNB for two reasons. Similar to SVM, MNB performs well with high-dimensional sparse data like our TF-IDF embeddings. The second reason why elect to use MNB here is because it is lightweight. Like I stated above, MNB’s core assumption of feature independence makes it computationally cheaper to run vs other models.</p>
</section>
</section>
</section>
<section id="classification-model-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="classification-model-pipeline">Classification Model Pipeline</h2>
<p>Below, I define the function <code>classification()</code>, that takes in the following parameters:</p>
<ul>
<li><code>df</code>: A pandas dataframe containing all of our data, including features and the target variable</li>
<li><code>target</code>: A string that allows us to define which variables in <code>df</code> that we want to use as the predictor (either ‘sentiment’ or ‘rating’)</li>
<li><code>selected_features</code>: A list object that allows me to subset different features in the data when running predictions</li>
<li><code>include_tfidf</code>: A boolean value that states whether or not we include the TF-IDF embeddings in our features</li>
<li><code>test_size</code>: Determines the percent of observations that we want to test on</li>
<li><code>random_state</code>: A random seed that we include for reproducibility</li>
<li><code>show_confusion_mat</code>: Boolean value indicating whether we want the function to display a confusion matrix</li>
</ul>
<p>The function works by first extracting which variables we will use as features when running predictions. If <code>include_tfidf</code> is set to true, then I apply sklearn’s <code>MinMaxScaler</code> object to my TF-IDF features in order to normalize their magnitude, as models like SVM and logistic regressions are sensitive to the scale of our input features. I elect to use <code>MinMaxScaler</code> over the standard scaler since models like Multinomial Naive Bayes require non-negative inputs (StandardScaler centers the data around mean 0, meaning some of the scaled values will be negative).</p>
<p>The function then splits the features and target into <code>X</code> and <code>y</code> dataframes, and uses scikit learn’s <code>train_test_split</code> function to further split the data into a training and testing set. From there, the function references which variable we want to predict. In cases where <code>target</code> is set to “sentiment”, we initialize <code>LogisticRegression</code> and <code>RandomForestClassifer</code> objects to perform binary classification. If <code>target</code> is defined as “rating”, we instead initialize <code>SVC</code> and <code>MultinomialNP</code> objects and continue forward with a multi-class prediction. In both cases, the function creates a dictionary called <code>models</code> that stores the name and configurations of our classifers.</p>
<p>After that, the we create a <code>results</code> dictionary that stores the results of each model. To run the models, I use a for loop that runs through each item (or model) in the <code>models</code> dictionary. During each model iteration, I create a subdictionary called <code>metrics</code> that stores the following results from our predictions:</p>
<p><strong>“Accuracy”:</strong> Meaures the proportion of correct predictions made</p>
<p><span class="math inline">\(\frac{\text{True Positives + True Negatives}}{\text{Total Samples}}\)</span></p>
<p><strong>“Precision”:</strong> Measures the proportion of true positives to all positive predictions made</p>
<p><span class="math inline">\(\frac{\text{True Positives}}{\text{True Positives + False Positives}}\)</span></p>
<p><strong>“Recall”:</strong> Measures the proportion of actual positives that our model(s) identified</p>
<p><span class="math inline">\(\frac{\text{True Positives}}{\text{True Positives + False Negatives}}\)</span></p>
<p><strong>“F1 Score”:</strong> Takes into consideration both Precision and Recall - focusing more on class-wise performance.<span class="citation" data-cites="F1Score"><sup><a href="#ref-F1Score" role="doc-biblioref">8</a></sup></span></p>
<p><span class="math inline">\(\frac{\text{True Positives}}{\text{True Positives + False Negatives}}\)</span></p>
<p>After we gather all of the results, I select the best model of the two by picking the one with the highest <strong>F1 Score</strong> value. I place the most emphasis on F1 Score here because our data set is heavily imbalanced. Specifically, there is an overwhelming amount of reviews (our multi-class target) with 5-star ratings, which also impacts our binary class (<code>sentiment</code>), as its value directly relates to <code>rating</code>.</p>
<div id="cell-31" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline for running binary and multi-class predictions</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classification(df, target<span class="op">=</span><span class="st">'sentiment'</span>, selected_features<span class="op">=</span><span class="va">None</span>, include_tfidf<span class="op">=</span><span class="va">False</span>, test_size <span class="op">=</span> <span class="fl">0.20</span>, random_state <span class="op">=</span> <span class="dv">5000</span>, show_confusion_matrix<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: select which features we want to use</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1(a) raise error if parameters are left blank</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> selected_features <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> <span class="kw">not</span> include_tfidf:</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Please specify either `selected_features` or set `include_tfidf` to True"</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1(b) combine features</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> []</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> selected_features:</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        features <span class="op">+=</span> selected_features</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> include_tfidf:</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        features <span class="op">+=</span> [col <span class="cf">for</span> col <span class="kw">in</span> df.columns <span class="cf">if</span> col.startswith(<span class="st">"tfidf_"</span>)]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1(c) Extract Features and Target variables</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> df[features]</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> df[target]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Train-Test Split</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span>test_size, random_state<span class="op">=</span>random_state)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: Scale TF-IDF features</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> include_tfidf:</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        tfidf_cols <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> X_train.columns <span class="cf">if</span> col.startswith(<span class="st">"tfidf_"</span>)]</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Scale</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>        X_train[tfidf_cols] <span class="op">=</span> scaler.fit_transform(X_train[tfidf_cols])</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>        X_test[tfidf_cols] <span class="op">=</span> scaler.fit_transform(X_test[tfidf_cols])</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: Initialize Models Based on our target variable</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> target <span class="op">==</span> <span class="st">'sentiment'</span>:</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        models <span class="op">=</span> {</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Logistic Regression"</span>: LogisticRegression(max_iter <span class="op">=</span> <span class="dv">1000</span>, random_state<span class="op">=</span>random_state),</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Random Forest"</span>: RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> target <span class="op">==</span> <span class="st">'rating'</span>:</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>        models <span class="op">=</span> {</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"SVM"</span>: SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>,</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>                       C <span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>                       gamma <span class="op">=</span><span class="st">'auto'</span>,</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>                       tol<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>                       shrinking<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>                       max_iter<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>                       cache_size<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>                       probability<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>                       random_state<span class="op">=</span>random_state),</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Naive Bayes"</span>: MultinomialNB()</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="co"># Only rating and sentiment are legal target variables in our data</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unsupported target var - please use either 'sentiment' or 'rating'."</span>)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 5: Train and evaluate the models</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {}</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> {}</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, model <span class="kw">in</span> models.items():</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>        model.fit(X_train, y_train)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store predictions in separate dictionary to reference later for confusion matrix</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>        predictions[model_name] <span class="op">=</span> y_pred</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Try 'predict_proba' if available (it won't be for out SVM because we want to speed up execution)</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>: </span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>            y_pred_prob <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">AttributeError</span>:</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>            y_pred_prob <span class="op">=</span> <span class="va">None</span></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate error metrics</span></span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> target <span class="op">==</span> <span class="st">'sentiment'</span>: <span class="co"># Metrics for binary classification</span></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> {</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Accuracy"</span>: accuracy_score(y_test, y_pred),</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Precision"</span>: precision_score(y_test, y_pred),</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Recall"</span>: recall_score(y_test, y_pred),</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>                <span class="st">"F1 Score"</span>: f1_score(y_test, y_pred),</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> target <span class="op">==</span> <span class="st">'rating'</span>: <span class="co"># Multiclass metrics</span></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> {</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Accuracy"</span>: accuracy_score(y_test, y_pred),</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Precision (Multi)"</span>: precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>),</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Recall (Multi)"</span>: recall_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>),</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>                <span class="st">"F1 Score (Multi)"</span>: f1_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add metrics to results dict</span></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>        results[model_name] <span class="op">=</span> {</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Model"</span>: model,</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Metrics"</span>: metrics</span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 6: Return the best model based on F1 score</span></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a>    f1_key <span class="op">=</span> <span class="st">"F1 Score"</span> <span class="cf">if</span> target <span class="op">==</span> <span class="st">'sentiment'</span> <span class="cf">else</span> <span class="st">'F1 Score (Multi)'</span> <span class="co"># Ensure we are maximizing the correct F1 Score</span></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> <span class="bu">max</span>(results, key<span class="op">=</span><span class="kw">lambda</span> k: results[k][<span class="st">"Metrics"</span>][f1_key])</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"BEST MODEL: </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"===========================</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Performance Metrics:"</span>)</span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> metric, value <span class="kw">in</span> results[best_model][<span class="st">"Metrics"</span>].items():</span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 7: Display Confusion Matrix if prompted</span></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_confusion_matrix:</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Confusion Matrix:"</span>)</span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>        c_mat <span class="op">=</span> confusion_matrix(y_test, predictions[best_model]) <span class="co"># Used stored predictions</span></span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>        sns.heatmap(c_mat, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>np.unique(y), yticklabels<span class="op">=</span>np.unique(y))</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"Predicted"</span>)</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f"Confusion Matrix: </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results[best_model]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="binary-classification-1" class="level2">
<h2 class="anchored" data-anchor-id="binary-classification-1">Binary Classification</h2>
<section id="tf-idf-features-only" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf-features-only">TF-IDF Features Only</h3>
<p>With our pipeline ready, let’s run a prediction of ‘sentiment’ using only our TF-IDF features:</p>
<div id="cell-34" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using only TF-IDF values for classification</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>bin_class_tfidf <span class="op">=</span> classification(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"sentiment"</span>, </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">True</span>, <span class="co"># Include all TF-IDF columns</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    show_confusion_matrix<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: Logistic Regression
===========================

Performance Metrics:
Accuracy: 0.8538
Precision: 0.8764
Recall: 0.9533
F1 Score: 0.9132

Confusion Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>Runtime: 1m 3.8s</em></p>
<p>In this case, the logistic regression performed the best, with around 85.4% accuracy in predicting review sentiment. It looks like most of our accuracy came from correctly identifying reviews with positive sentiment.</p>
</section>
<section id="non-tf-idf-features" class="level3">
<h3 class="anchored" data-anchor-id="non-tf-idf-features">Non TF-IDF Features</h3>
<p>Now, lets try to run a prediction using only <code>vote</code>, <code>verified</code>, and <code>product_id</code> as our features:</p>
<div id="cell-36" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using 'vote','verified', and 'product_id' features for classification</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>bin_class_three_features <span class="op">=</span> classification(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"sentiment"</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    selected_features<span class="op">=</span>[<span class="st">'vote'</span>,<span class="st">'verified'</span>,<span class="st">'product_id'</span>],</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">False</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: Logistic Regression
===========================

Performance Metrics:
Accuracy: 0.8071
Precision: 0.8071
Recall: 1.0000
F1 Score: 0.8933</code></pre>
</div>
</div>
<p><em>Runtime: 16.2s</em></p>
<p>When using only ‘vote’, ‘verified’, and ‘product_id’, our model performance drops to around 80% prediction accuracy - meaning the inclusion of our TF-IDF embeddings is likely crucial to boosting model performance</p>
</section>
<section id="all-features" class="level3">
<h3 class="anchored" data-anchor-id="all-features">All Features</h3>
<p>Next, I’ll test out the models using the three features above plus our TF-IDF values:</p>
<div id="cell-38" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using all features</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>bin_class_all_features <span class="op">=</span> classification(</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"sentiment"</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    selected_features<span class="op">=</span>[<span class="st">'vote'</span>,<span class="st">'verified'</span>,<span class="st">'product_id'</span>],</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: Logistic Regression
===========================

Performance Metrics:
Accuracy: 0.8547
Precision: 0.8756
Recall: 0.9558
F1 Score: 0.9139</code></pre>
</div>
</div>
<p><em>Runtime: 1m 54.3s</em></p>
<p>Not much of an improvement compared to our prediction using only TF-IDF. The inclusion of our other features only slightly improved our prediction accuracy.</p>
</section>
</section>
<section id="multi-class-prediction" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction">Multi-Class Prediction</h2>
<p>Let’s move forward now to predicting the rating for each review using our predefined pipeline. The only difference here is that I set the “target” parameter to <code>rating</code>, which tells our pipline to run multi-class predictions. Here we go!</p>
<section id="tf-idf-features-only-1" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf-features-only-1">TF-IDF Features Only</h3>
<div id="cell-42" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using only TF-IDF values for classification</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>mult_class_tfidf <span class="op">=</span> classification(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf, </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"rating"</span>, </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">True</span>, <span class="co"># Include all TF-IDF columns</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    show_confusion_matrix<span class="op">=</span><span class="va">True</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: SVM
===========================

Performance Metrics:
Accuracy: 0.5093
Precision (Multi): 0.3096
Recall (Multi): 0.2678
F1 Score (Multi): 0.2692

Confusion Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-20-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>Runtime: 7m 9.5s</em></p>
<p>Unfortunately, it looks like our multi-class model trained on only TF-IDF features does not perform as well as the binary classifier - with only 50% accuracy in correct rating assignments. When looking at the confusion matrix, it appears that the model did the best at correcly identifying 5-star reviews. This result should not be surprising, given the disproportionately large amount of 5 star reviews in the data.</p>
</section>
<section id="non-tf-idf-features-1" class="level3">
<h3 class="anchored" data-anchor-id="non-tf-idf-features-1">Non TF-IDF Features</h3>
<p>For our next iteration, let’s train the multi-class model on only the non TF-IDF features to see if that changes anything:</p>
<div id="cell-44" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating using only vote, verified, and product_id</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>mult_class_three_features <span class="op">=</span> classification(</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"rating"</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    selected_features<span class="op">=</span>[<span class="st">'vote'</span>,<span class="st">'verified'</span>,<span class="st">'product_id'</span>], </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    show_confusion_matrix<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: SVM
===========================

Performance Metrics:
Accuracy: 0.6202
Precision (Multi): 0.2184
Recall (Multi): 0.2029
F1 Score (Multi): 0.1732

Confusion Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-21-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>Runtime: 54.4s</em></p>
<p>When using only the non TF-IDF features (<code>product_id</code>, <code>vote</code>, <code>verified</code>), our model’s performance increases to around 62% accuracy. Still a far cry away from our binary class performance.</p>
</section>
<section id="all-features-1" class="level3">
<h3 class="anchored" data-anchor-id="all-features-1">All Features</h3>
<p>Finally, let’s try to run a prediction using all of our features:</p>
<div id="cell-47" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating using all features</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>mult_class_all_features <span class="op">=</span> classification(</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf, </span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"rating"</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    selected_features<span class="op">=</span>[<span class="st">'vote'</span>,<span class="st">'verified'</span>,<span class="st">'product_id'</span>], </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    show_confusion_matrix<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: Naive Bayes
===========================

Performance Metrics:
Accuracy: 0.6485
Precision (Multi): 0.4263
Recall (Multi): 0.2663
F1 Score (Multi): 0.2694

Confusion Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>Runtime: </em></p>
<p>Our full feature model slightly outperforms the other two, with around 65% accuracy. While an improvement, the results still leave more to be desired. In all three of our multi-class predictions, the model achieves most of its accuracy from correctly classifying 5-star ratings. In all other cases, the models consistently fall flat in properly classifying lower star reviews. To try and correct this, I will try the undersampling technique outlined in Magdelano et al.<span class="citation" data-cites="Magdelano2024"><sup><a href="#ref-Magdelano2024" role="doc-biblioref">9</a></sup></span> In this method, we create a new dataframe called <code>reviews_tfidf_undersampled</code>, in which the counts of our five review classes are equal (i.e.&nbsp;20% 1-star, 20% 2-star, etc.) The goal here is to provide our multi-class model with a balanced number of each target class.</p>
</section>
</section>
<section id="multi-class-prediction-with-undersampling" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-prediction-with-undersampling">Multi-Class Prediction with Undersampling</h2>
<p>Let’s first check the counts of each rating in the data:</p>
<div id="cell-50" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>reviews_tfidf[<span class="st">'rating'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>rating
5    64002
4    16802
3     7691
1     6902
2     4603
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>It looks like our minimum value is for 1-star ratings, making up only 4603 reviews. With that in mind, let’s create a new dataframe <code>reviews_tfidf_undersampled</code> where the value count for each rating class is this number.</p>
<div id="cell-52" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting minimum count</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>min_count <span class="op">=</span> reviews_tfidf[<span class="st">'rating'</span>].value_counts().<span class="bu">min</span>()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an undersampled data frame</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>reviews_tfidf_undersamlped <span class="op">=</span> (</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Here, we are grouping by 'rating' and randomly sampling 4603 observations from each group</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    reviews_tfidf.groupby(<span class="st">'rating'</span>).<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(n<span class="op">=</span>min_count, random_state<span class="op">=</span><span class="dv">5000</span>)).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing new counts</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>reviews_tfidf_undersamlped[<span class="st">'rating'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>rating
1    4603
2    4603
3    4603
4    4603
5    4603
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>As a quick check to see if this solves our proble - let’s run the full feature model above, but this time we will use our undersampled data set</p>
<section id="all-features-unsampled" class="level3">
<h3 class="anchored" data-anchor-id="all-features-unsampled">All Features, Unsampled</h3>
<p>Running multi-class prediction, using all features and undersampled data set:</p>
<div id="cell-55" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting rating using all features</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>mult_class_all_features_undersampled <span class="op">=</span> classification(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    df<span class="op">=</span>reviews_tfidf_undersamlped, </span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    target<span class="op">=</span><span class="st">"rating"</span>,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    selected_features<span class="op">=</span>[<span class="st">'vote'</span>,<span class="st">'verified'</span>,<span class="st">'product_id'</span>], </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    include_tfidf<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    show_confusion_matrix<span class="op">=</span><span class="va">True</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BEST MODEL: Naive Bayes
===========================

Performance Metrics:
Accuracy: 0.4063
Precision (Multi): 0.3975
Recall (Multi): 0.4070
F1 Score (Multi): 0.3992

Confusion Matrix:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-25-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><em>Runtime: 1m 26.4s</em></p>
<p>Not the result we were looking for. Like I stated above, in prior models it looked like most of the prediction accuracy came from properly identifying 5 star reviews. However, when we used an undersampled data set, we set the proportion of those reviews equal to all of the others.</p>
<p>In other words, I was able to solve the problem of our model overly focusing on the dominant 5-star class, but this came at the expense of overall accuracy (now only 40%). An interesting point to note is that for all cases when we used undersampling, the SVM model performed the best. Post-undersampling however, the Multinomial Naive Bayes model emerged as the best model - likely because its probabilistic approach to class labeling worked better when our distribution of different ratings was equal.</p>
<p>On a more positive note, our the confusion matrix from the undersample prediction showed improved performance in predicting the previously underrepresented classes (especially 1-stars), which were previously overshadowed by the majority 5-star class in our old data set.</p>
<div id="cell-57" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>reviews_tfidf.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">product_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">sentiment</th>
<th data-quarto-table-cell-role="th">text_clean</th>
<th data-quarto-table-cell-role="th">summary_clean</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">summary</th>
<th data-quarto-table-cell-role="th">polarity</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">tfidf_490</th>
<th data-quarto-table-cell-role="th">tfidf_491</th>
<th data-quarto-table-cell-role="th">tfidf_492</th>
<th data-quarto-table-cell-role="th">tfidf_493</th>
<th data-quarto-table-cell-role="th">tfidf_494</th>
<th data-quarto-table-cell-role="th">tfidf_495</th>
<th data-quarto-table-cell-role="th">tfidf_496</th>
<th data-quarto-table-cell-role="th">tfidf_497</th>
<th data-quarto-table-cell-role="th">tfidf_498</th>
<th data-quarto-table-cell-role="th">tfidf_499</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>27766</td>
<td>5</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
<td>0.321675</td>
<td>...</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.219799</td>
<td>0.0</td>
</tr>
</tbody>
</table>

<p>1 rows × 510 columns</p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="section-3-regression" class="level1">
<h1>Section 3: Regression</h1>
<p><strong>Model Selection</strong></p>
<p><strong>Modeling Pipeline</strong></p>
<p><strong>Ridge Regression</strong></p>
<p><strong>Random Forest Regressor</strong></p>
<section id="model-selection-1" class="level2">
<h2 class="anchored" data-anchor-id="model-selection-1">Model Selection</h2>
<section id="linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression">Linear Regression</h3>
<p><strong><em>Predicting Review Polarity</em></strong></p>
<section id="ridge-regression" class="level4">
<h4 class="anchored" data-anchor-id="ridge-regression">Ridge Regression</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
<p>The ridge regression is variant of the traditional <a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> that is specifically designed to handle cases when features are highly correlated. In traditional linear regressions, the model fits the data using the <a href="https://en.wikipedia.org/wiki/Least_squares">least squares</a> approach, whereing the resulting best fit line minimizes the amount of noise in the data. The ridge regression works in a similar way, but instead of just minimizing noise, ridge regressions use a form of constrained optimization that takes the traditional least squares error and applies a regularization term <span class="math inline">\(\lambda\)</span> that works by puninshing larger coefficient values, effectively reducing multicolinearity in the data.<span class="citation" data-cites="Ridge"><sup><a href="#ref-Ridge" role="doc-biblioref">10</a></sup></span></p>
<p><strong>Linear Regression RSS:</strong> <span class="math inline">\(RSS \ = \sum_{i=1}^{n} (y_{i} - \hat{y_{i}})^2\)</span></p>
<p><strong>Ridge Regression RSS:</strong><span class="citation" data-cites="Ridge"><sup><a href="#ref-Ridge" role="doc-biblioref">10</a></sup></span> <span class="math inline">\(RSS \ = \sum_{i=1}^{n} (y_{i} - \hat{y_{i}})^2 + \lambda \sum_{j=1}^{p} \beta_{j}^2\)</span></p>
<ul>
<li><strong>Model Rationale</strong></li>
</ul>
<p>In the context of predicting polarity using our data, I elect to use a ridge regression because our TF-IDF matrix contains embeddings from very short and repetitive documents. By that, I mean our collection of Amazon reviews are all very short and have a great deal of frequently repeated terms, which runs the risk of their respective TF-IDF values being highly correlated. Like I said before, ridge regressions work to reduce this multicolinearity.</p>
</section>
<section id="random-forest-regression" class="level4">
<h4 class="anchored" data-anchor-id="random-forest-regression">Random Forest Regression</h4>
<ul>
<li><strong>Overview</strong></li>
</ul>
</section>
</section>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<section id="classification" class="level2">
<h2 class="anchored" data-anchor-id="classification">Classification</h2>
<section id="binary-classification-2" class="level3">
<h3 class="anchored" data-anchor-id="binary-classification-2">Binary Classification</h3>
<ul>
<li>Logistic regression outperformed Random Forest in all modeling scenarios</li>
<li>Highest prediction accuracy (85.47%) came from using all features</li>
</ul>
</section>
<section id="multi-class-classification-1" class="level3">
<h3 class="anchored" data-anchor-id="multi-class-classification-1">Multi-class Classification</h3>
<ul>
<li>MNB model had highest overall accuracy in predicting rating score (64.85%) - when all features were included from full data set</li>
<li>Most of the accuracy from our multi-class predictions came from properly identifying the dominant review class (5)</li>
<li>When using undersampling to correct for unbalanced classes, accuracy plummeted to 40%</li>
<li>Undersampling did however allow the models to perform better in predicting previously underrepresented classes</li>
</ul>
</section>
<section id="challenges" class="level3">
<h3 class="anchored" data-anchor-id="challenges">Challenges</h3>
<ul>
<li><strong>Confusion Matrix Redundancy</strong></li>
</ul>
<p>Old confusion matrix code had me running the best model again to extract predictions, so I instead opted to use a <code>predictions</code> dictionary, that stores the results for each model allowing me to reference them down the line when building the confusion matrix (without running the best model twice).</p>
<ul>
<li><strong>SVM Execution Time</strong></li>
</ul>
<p>When running multi-class classification, my initial run-times were over 3 hours each. I was able to hone in on the problem being SVM, and its difficulty with handling larger datasets or when it tries to use non-linear transformations (like the radius basis function).</p>
<p><strong>Config 1:</strong> <code>SVC(kernel="rbf", probability=True) #with Unscaled features</code> - In this configuration, I used the radial basis function (RBF) kernel for transformations - <em>Runtime: &gt; 3 hours</em></p>
<p><strong>Config 2:</strong> <code>SVC(kernel="linear", probability=True) #with Unscaled features</code> - For the second config, I changed the kernel to “linear”, for <a href="https://scikit-learn.org/1.5/modules/svm.html">faster</a> performance - <em>Runtime: &gt; 3 hours</em></p>
<p><strong>Config 3:</strong> <code>SVC(kernel="linear", probability=True) #with MinMaxScaled features</code> - Here, I tried scaling the features using sklearn’s <a href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">MinMaxScaler</a> to reduce complexity of TF-IDF values - <em>Runtime: &gt; 3 hours</em></p>
<p><strong>Config 5:</strong> <code>SVC(kernel='rbf',C=0.5,gamma ='auto',tol=0.01,shrinking=False,max_iter=1000,cache_size=1000,probability=False) #with MinMaxScaled features</code> - At this point, I consulted OpenAI’s ChatGPT-4o model to help create the fastest SVM configuration.<span class="citation" data-cites="gpt4o_SVM"><sup><a href="#ref-gpt4o_SVM" role="doc-biblioref">11</a></sup></span></p>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-IBMsupervised" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><a href="https://www.ibm.com/topics/supervised-learning">What is supervised learning?</a></div>
</div>
<div id="ref-TFIDF" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><a href="https://www.activeloop.ai/resources/glossary/term-frequency-inverse-document-frequency-tf-idf/#:~:text=The%20TF%20is%20calculated%20by,of%20documents%20containing%20the%20term">Term frequency-inverse document frequency (TF-IDF)</a>.</div>
</div>
<div id="ref-scikitTFIDF" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><a href="https://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer">Scikit-learn TfidfVectorizer documentation</a>.</div>
</div>
<div id="ref-sigmoid" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><a href="https://www.linkedin.com/pulse/understanding-sigmoid-function-logistic-regression-piduguralla/">Understanding the sigmoid function in logistic regression: Mapping inputs to probabilities</a>.</div>
</div>
<div id="ref-decisiontrees" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><a href="https://www.ibm.com/topics/decision-trees">What is a decision tree?</a></div>
</div>
<div id="ref-SVM" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><a href="https://www.ibm.com/topics/support-vector-machine">What are SVMs?</a></div>
</div>
<div id="ref-MNB" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><a href="https://www.ibm.com/topics/naive-bayes#:~:text=Multinomial%20Na%C3%AFve%20Bayes%20(MultinomialNB)%3A,use%20cases%2C%20like%20spam%20classification">What are naïve bayes classifiers?</a></div>
</div>
<div id="ref-F1Score" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><a href="https://www.v7labs.com/blog/f1-score-guide">F1 score in machine learning: Intro &amp; calculation</a>.</div>
</div>
<div id="ref-Magdelano2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Magdaleno, D., Montes, M., Estrada, B. &amp; Ochoa-Zezzatti, A. A GPT-based approach for sentiment analysis and bakery rating prediction. in <em>Advances in computational intelligence. MICAI 2023 international workshops</em> (eds. Calvo, H. et al.) 61–76 (Springer Nature Switzerland, 2024).</div>
</div>
<div id="ref-Ridge" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><a href="https://towardsdatascience.com/from-linear-regression-to-ridge-regression-the-lasso-and-the-elastic-net-4eaecaf5f7e6#:~:text=Ridge%20regression%20works%20with%20an,can%20still%20use%20gradient%20descent">From linear regression to ridge regression, the lasso, and the elastic net</a>.</div>
</div>
<div id="ref-gpt4o_SVM" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">‘Prompt: Can you give me the most computationally efficient configuration of sklearn’s SVC object?‘ ChatGPT, version-4o, OpenAI, dec-13, 2024, chat.openai.com.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>