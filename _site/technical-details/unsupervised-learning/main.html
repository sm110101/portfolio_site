<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Unsupervised Learning – Sean Morris</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/sm_logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Unsupervised Learning – Sean Morris">
<meta property="og:description" content="">
<meta property="og:image" content="assets/sm_logo.png">
<meta property="og:site_name" content="Sean Morris">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/sm_logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sean Morris</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../report/report.html"> 
<span class="menu-text">Report</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-technical-details" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Technical details</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-technical-details">    
        <li>
    <a class="dropdown-item" href="../../technical-details/data-collection/main.html">
 <span class="dropdown-text">Data-collection</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/data-cleaning/main.html">
 <span class="dropdown-text">Data-cleaning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/eda/main.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/unsupervised-learning/main.html">
 <span class="dropdown-text">Unsupervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/supervised-learning/main.html">
 <span class="dropdown-text">Supervised Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/progress-log.html">
 <span class="dropdown-text">Progress Log</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../technical-details/llm-usage-log.html">
 <span class="dropdown-text">LLM usage Log</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/spm122/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/sm110101"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sm110101"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/sean.morriss/"> <i class="bi bi-instagram" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#dimension-reduction" id="toc-dimension-reduction" class="nav-link" data-scroll-target="#dimension-reduction">Dimension Reduction</a>
  <ul class="collapse">
  <li><a href="#pca" id="toc-pca" class="nav-link" data-scroll-target="#pca">PCA</a></li>
  <li><a href="#t-sne" id="toc-t-sne" class="nav-link" data-scroll-target="#t-sne">t-SNE</a></li>
  </ul></li>
  <li><a href="#clustering" id="toc-clustering" class="nav-link" data-scroll-target="#clustering">Clustering</a>
  <ul class="collapse">
  <li><a href="#k-means" id="toc-k-means" class="nav-link" data-scroll-target="#k-means">K-Means</a></li>
  <li><a href="#hierarchical-clustering" id="toc-hierarchical-clustering" class="nav-link" data-scroll-target="#hierarchical-clustering">Hierarchical Clustering</a></li>
  <li><a href="#dbcscan" id="toc-dbcscan" class="nav-link" data-scroll-target="#dbcscan">DBCSCAN</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a>
  <ul class="collapse">
  <li><a href="#loading-in-data-and-libraries" id="toc-loading-in-data-and-libraries" class="nav-link" data-scroll-target="#loading-in-data-and-libraries">Loading in Data and Libraries</a></li>
  <li><a href="#baseline-tests" id="toc-baseline-tests" class="nav-link" data-scroll-target="#baseline-tests">Baseline Tests</a>
  <ul class="collapse">
  <li><a href="#basline-t-sne-vs-pca" id="toc-basline-t-sne-vs-pca" class="nav-link" data-scroll-target="#basline-t-sne-vs-pca">Basline: t-SNE vs PCA</a></li>
  </ul></li>
  <li><a href="#parameter-optimization-dimension-reduction" id="toc-parameter-optimization-dimension-reduction" class="nav-link" data-scroll-target="#parameter-optimization-dimension-reduction">Parameter Optimization: Dimension Reduction</a>
  <ul class="collapse">
  <li><a href="#test-1-intermediate-pca" id="toc-test-1-intermediate-pca" class="nav-link" data-scroll-target="#test-1-intermediate-pca">Test 1: Intermediate PCA</a></li>
  <li><a href="#test-2-no-intermediate-pca" id="toc-test-2-no-intermediate-pca" class="nav-link" data-scroll-target="#test-2-no-intermediate-pca">Test 2: No Intermediate PCA</a></li>
  <li><a href="#test-3-adjusting-perplexity" id="toc-test-3-adjusting-perplexity" class="nav-link" data-scroll-target="#test-3-adjusting-perplexity">Test 3: Adjusting Perplexity</a></li>
  <li><a href="#test-4-adjusting-document-frequency-in-tf-idf-embedding" id="toc-test-4-adjusting-document-frequency-in-tf-idf-embedding" class="nav-link" data-scroll-target="#test-4-adjusting-document-frequency-in-tf-idf-embedding">Test 4: Adjusting Document Frequency in TF-IDF Embedding</a></li>
  <li><a href="#test-5-tweaking-number-of-iterations-in-t-sne" id="toc-test-5-tweaking-number-of-iterations-in-t-sne" class="nav-link" data-scroll-target="#test-5-tweaking-number-of-iterations-in-t-sne">Test 5: Tweaking Number of Iterations in t-SNE</a></li>
  <li><a href="#fine-tuning-perplexity" id="toc-fine-tuning-perplexity" class="nav-link" data-scroll-target="#fine-tuning-perplexity">Fine-tuning Perplexity</a></li>
  </ul></li>
  <li><a href="#clustering-1" id="toc-clustering-1" class="nav-link" data-scroll-target="#clustering-1">Clustering</a>
  <ul class="collapse">
  <li><a href="#kmeans-clustering" id="toc-kmeans-clustering" class="nav-link" data-scroll-target="#kmeans-clustering">KMeans Clustering</a></li>
  </ul></li>
  <li><a href="#hierarchical-agglomerative-clustering" id="toc-hierarchical-agglomerative-clustering" class="nav-link" data-scroll-target="#hierarchical-agglomerative-clustering">Hierarchical (Agglomerative) Clustering</a></li>
  <li><a href="#dbscan" id="toc-dbscan" class="nav-link" data-scroll-target="#dbscan">DBSCAN</a></li>
  <li><a href="#plotting-clustering-results" id="toc-plotting-clustering-results" class="nav-link" data-scroll-target="#plotting-clustering-results">Plotting Clustering Results</a>
  <ul class="collapse">
  <li><a href="#kmeans" id="toc-kmeans" class="nav-link" data-scroll-target="#kmeans">Kmeans</a></li>
  </ul></li>
  <li><a href="#hierarchical-clustering-1" id="toc-hierarchical-clustering-1" class="nav-link" data-scroll-target="#hierarchical-clustering-1">Hierarchical Clustering</a></li>
  <li><a href="#dbscan-1" id="toc-dbscan-1" class="nav-link" data-scroll-target="#dbscan-1">DBSCAN</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges">Challenges</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Unsupervised Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><br> <br></p>
<section id="overview" class="level1">
<h1>Overview</h1>
<section id="dimension-reduction" class="level2">
<h2 class="anchored" data-anchor-id="dimension-reduction">Dimension Reduction</h2>
<section id="pca" class="level3">
<h3 class="anchored" data-anchor-id="pca">PCA</h3>
<p>In this section, I will use text frequency-inverse document TF-IDF as my embedding method to vectorize our reviews data. My rationale for using only TF-IDF, comes from the questionable results obtained when I used only the bag-of-words approach in the <a href="../../technical-details/eda/main.html">EDA</a> section. Specifically, when looking only at single term frequency per review class, there were multiple instances where meaningless words appeared most frequently across all review scores. I was able to address this issue by instead bagging pairs of words (bigrams) instead, which yielded more intuitive results. Regardless, I chose to only use TF-IDF in this section because it considers both how often a term appears in a single review (Term Frequency), and how rare the term is across all reviews (Inverse Document Frequency). This two-pronged approach punishes words that are common across the entire review corpus, while favoring those that are less common and therefore may have greater meaning. For further context on TF-IDF, see the equations outlined in the literature review on the <a href="../../index.html">Home</a> page.</p>
<p>After embedding the review text, I will leverage several different unsupervised learning techniques. To begin, I use two types of dimension reduction techniques to collapse the high-dimensional tf-idf matrix into a low-dimensional space for easier visualization. For this, I will use Principal Components Analysis (PCA) and t-distributed Stochastic Neighbor Embedding. In case you are unfamiliar with these two topics - PCA works by identifying an axes in high-dimensional space, along which the preserved variance of the data is maximized. These so-called “principal” components are eigenvectors of the covariance matrix, and their selection (i.e.&nbsp;how many principal components we take) depends on the respective share of total variance preserved by their eigenvalues<span class="citation" data-cites="EigenPCA"><sup><a href="#ref-EigenPCA" role="doc-biblioref">1</a></sup></span>.</p>
<p><strong>Here is a helpful visualization of what is going on in PCA:</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/pca.gif" class="img-fluid" width="600"> <br> Source: <a href="https://builtin.com/data-science/step-step-explanation-principal-component-analysis">Builtin</a></p>
</section>
<section id="t-sne" class="level3">
<h3 class="anchored" data-anchor-id="t-sne">t-SNE</h3>
<p>On the other hand, t-SNE takes a non-linear, probabilistic approach to dimension reduction that works in two stages. First t-SNE constructs probability distributions over different pairs of high-dimensional points, where it then assigns higher probabilities to similar points and lower probabilities to dissimilar points<span class="citation" data-cites="WikiTSNE"><sup><a href="#ref-WikiTSNE" role="doc-biblioref">2</a></sup></span>. From there, t-SNE creates similar probability distributions in lower dimensional space, and shrinks the difference between the two distributions by minimizing the Kullback-Leibler (KL) divergence between the two. In simple terms, the KL divergence simply measures the difference between two different probability distributions<span class="citation" data-cites="WikiKL"><sup><a href="#ref-WikiKL" role="doc-biblioref">3</a></sup></span>. T-SNE also requires the use of a <code>perplexity</code> hyperparameter, which represents a guess as to how many close neighbors a given point should have, or the “balance between preserving the global and local structure of the data”<span class="citation" data-cites="perplexity"><sup><a href="#ref-perplexity" role="doc-biblioref">4</a></sup></span>. Feel free to head over <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">here</a> for a more robust explanation of t-SNE and KL divergence.</p>
<p><strong>Example of how <code>perplexity</code> Influences t-SNE Results</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/perplexity.png" class="img-fluid" width="600"> <br> Source: <a href="https://www.scdiscoveries.com/blog/knowledge/what-is-t-sne-plot/">Single Cell Discoveries</a></p>
</section>
</section>
<section id="clustering" class="level2">
<h2 class="anchored" data-anchor-id="clustering">Clustering</h2>
<p>Once the data is properly collapsed into a lower-dimensional space, I will apply several clustering methods in order to better understand how different pieces of text group together. For this, I will use K-Means Clustering, Hierarchical Clustering, and DBSCAN. The goal for using clustering methods within the context of this study is to uncover underlying patterns in text for different review rating scores.</p>
<section id="k-means" class="level3">
<h3 class="anchored" data-anchor-id="k-means">K-Means</h3>
<p>As a first step, I will apply a K-Means clustering algorithm to the dimension-reduced data. The K-Means algorithm starts by randomly selecting <span class="math inline">\(k\)</span> points in the dataset, where <span class="math inline">\(k\)</span> is a hyperparameter that we can optimize by using the elbow method (covered below). From there, the algorithm takes these <span class="math inline">\(k\)</span> centroids and calculates their distance to all other points in the data set, assigning all of the closest points to their respective centroid. For my distance metric, I elect use Euclidean distance<span class="citation" data-cites="eucdistance"><sup><a href="#ref-eucdistance" role="doc-biblioref">5</a></sup></span>:</p>
<p><span class="math display">\[
\text{for a point} \ x = (x_1, x_2, ..., x_n) \ \text{and centroid} \ \mu = (\mu_1, \mu_2, \mu_n) \ \text{their distance} \ d(x,\mu) = \sqrt{\sum_{i=1}^{n}(x_{i}-\mu_{i})^2}
\]</span></p>
<p>After all data points have been assigned to their initial clusters, we calculate the mean of all data points for a given cluster<span class="citation" data-cites="Week8Slides"><sup><a href="#ref-Week8Slides" role="doc-biblioref">6</a></sup></span>:</p>
<p><span class="math display">\[
\mu_{j}^{\text{new}} \leftarrow \frac{1}{|S_{j}|} \sum_{x_{i} \in{S_{j}}} x_{i}
\]</span></p>
<p>From there, we repeat our distance calculation and cluster re-assignment until convergence.</p>
<p><strong>Example of K-Means Convergence</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/kmeans.gif" class="img-fluid" width="400"> <br> Source: <a href="https://commons.wikimedia.org/wiki/File:K-means_convergence.gif">Wikipedia</a></p>
</section>
<section id="hierarchical-clustering" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-clustering">Hierarchical Clustering</h3>
<p>In the next step of the process, I will use hierarchical clustering to help extract text groupings from the data. Unlike K-Means clustering’s reliance on centroids, hierarchical clustering uses a tree-based model of distance called a ‘dendrogram’ to analyze similarity of data points. The dendrogram is constructed through an iterative process, where it progressively combines or splits up clusters based on the similarity of points within them. The process ends either when all points in the data are combined into a single cluster, or when a predefined number of clusters are formed.</p>
<p>There are two different types of hierarchical clustering, agglomerative and divisive. Here, I elect to use agglomerative or “bottom-up” hierarchical clustering to group my data points. Take for example the case when our data set is the the set letters [A,B,C,D,E,F]. An agglomerative clustering model starts by treating each letter as its own cluster. In the next step, the model combines the most similar clusters. For instance, the model may merge together clusters B and C, and D and E, resulting in the new clusters [A, BC, DE, F]. From there, the model calculates cluster distances again, merging clusters DE and F, leaving us with [A, BC, DEF]. Eventually, the model will merge all clusters such that we have a single cluster [ABCDEF] (Thanks to <a href="https://www.geeksforgeeks.org/hierarchical-clustering/">geeksforgeeks</a> for this example).</p>
<p><strong>Simple Example of Agglomerative Clustering:</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/agglomerative.png" class="img-fluid" width="400"> <br> Source: <a href="https://www.geeksforgeeks.org/hierarchical-clustering/">GeeksforGeeks</a></p>
</section>
<section id="dbcscan" class="level3">
<h3 class="anchored" data-anchor-id="dbcscan">DBCSCAN</h3>
<p>Density-based spatial clustering of applications with noise, or DBSCAN is a density-based approach to clustering data points. I elect to use this method of clustering in my analysis because the two methods above (K-Means and Agglomerative) are geared towards finding spherical- or convex-shaped clusters (shapes that are better-defined and less noisy). In the case of low-dimensional representations of text data, it is highly likely that clusters will not be well-defined, and therefore may require an alternative method for extracting them. That is precisely where DBSCAN comes into play. The DBSCAN algorithm requires <code>eps</code> and <code>MinPts</code> parameters, where eps “defines the neighborhood around data points,” wherein the distance between two points that are close to each other (neighbors) approximately equal to <code>eps</code><span class="citation" data-cites="eps"><sup><a href="#ref-eps" role="doc-biblioref">7</a></sup></span>. The parameter <code>MinPts</code> simply defines the minimum number of data points within the eps radius, where larger data sets typically require a higher value of <code>MinPts</code><span class="citation" data-cites="eps"><sup><a href="#ref-eps" role="doc-biblioref">7</a></sup></span>.</p>
<p><strong>Example of DBSCAN Clustering</strong> <br> <img src="../../xtra/multiclass-portfolio-website/images/DBSCAN.gif" class="img-fluid" width="400"> <br> Source: <a href="https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html">KDnuggets</a></p>
</section>
</section>
</section>
<section id="code" class="level1">
<h1>Code</h1>
<section id="loading-in-data-and-libraries" class="level2">
<h2 class="anchored" data-anchor-id="loading-in-data-and-libraries">Loading in Data and Libraries</h2>
<p>Here, I begin by loading in all of the necessary libraries for dimension reduction and clustering. I am using the <a href="https://scikit-learn.org/stable/"><code>sklearn</code></a> package for KMeans, DBSCAN, and agglomerative clustering, the <code>plotly</code> <a href="https://plotly.com/python/">python library</a> for displaying interactive visualizations, and <code>pandas</code> for data manipulation. Below, I begin by unzipping the data file we worked with in the <a href="../../technical-details/eda/main.html">EDA</a> section.</p>
<div id="cell-3" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loading and manipulation packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gzip</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Dimension reduction packages</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer, TfidfVectorizer</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering packages</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans, DBSCAN, AgglomerativeClustering</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Data visualization packages</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.figure_factory <span class="im">as</span> ff</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Ignoring warnings</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pathway to raw data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data_path <span class="op">=</span> <span class="st">"../../data/processed-data/reviews_short.csv.gz"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Unzip the CSV file</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(data_path, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read the CSV file into a dataframe</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    reviews <span class="op">=</span> pd.read_csv(f)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>reviews.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">reviewRating</th>
<th data-quarto-table-cell-role="th">vote</th>
<th data-quarto-table-cell-role="th">verified</th>
<th data-quarto-table-cell-role="th">reviewTime</th>
<th data-quarto-table-cell-role="th">reviewerID</th>
<th data-quarto-table-cell-role="th">productID</th>
<th data-quarto-table-cell-role="th">reviewerName</th>
<th data-quarto-table-cell-role="th">reviewText</th>
<th data-quarto-table-cell-role="th">summary</th>
<th data-quarto-table-cell-role="th">reviewTextClean</th>
<th data-quarto-table-cell-role="th">summaryClean</th>
<th data-quarto-table-cell-role="th">binary_target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.0</td>
<td>2</td>
<td>False</td>
<td>2016-06-17</td>
<td>A7HY1CEDK0204</td>
<td>B00I9GYG8O</td>
<td>Jor El</td>
<td>If you're looking for Cinema 4K capabilities o...</td>
<td>Filmmakers will love this camera.</td>
<td>youre looking cinema k capabilities budget cam...</td>
<td>filmmakers love camera</td>
<td>positive</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="baseline-tests" class="level2">
<h2 class="anchored" data-anchor-id="baseline-tests">Baseline Tests</h2>
<p>In this section, I vectorize our cleaned text data using the <code>TfidfVectorizer</code> object found in the <a href="https://scikit-learn.org/stable/"><code>sklearn</code></a> library. Like I said previously, I experienced some issues relating to poor performance when applying <code>CountVectorizer</code> to single terms. Therefore, in this section, I elect to run the TfidfVectorizer` on single words and bigrams, as its consideration of word weights allows it to punish terms that are commonly found across all classes (review scores in this case).</p>
<p><strong>The plan going forward:</strong></p>
<ul>
<li>Conduct some preliminary baseline tests using PCA and t-SNE, and see which performs better when given our reviews data</li>
<li>Take the higher performer of the two, and build out a refined function that can be used to iteratively test different parameters</li>
<li>Once I find a result that I like, save it to a new variable for modeling down the line</li>
<li>Perform clustering on the two best sets of reduced data.</li>
</ul>
<section id="basline-t-sne-vs-pca" class="level3">
<h3 class="anchored" data-anchor-id="basline-t-sne-vs-pca">Basline: t-SNE vs PCA</h3>
<p>To start off, let’s create two simple plots of the data, using each of our two different dimension reduction techniques and TF-IDF embedding. To speed up the process, I will add a <code>N_SAMPLES</code> constant to allow for faster execution</p>
<p><strong>Sample TF-IDF Matrix</strong></p>
<div id="cell-8" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>N_SAMPLES <span class="op">=</span> <span class="dv">2500</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>sampled_reviews <span class="op">=</span> reviews.sample(n<span class="op">=</span>N_SAMPLES, random_state<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Using tf-idf embedding</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> TfidfVectorizer(max_features <span class="op">=</span> <span class="dv">500</span>, ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>)) <span class="co"># Default params for our case: maximum features = 500 and consider both unigrams and bigrams </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>X_tfidf <span class="op">=</span> tfidf.fit_transform(sampled_reviews[<span class="st">'reviewTextClean'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Standard PCA and t-SNE Reduction</strong></p>
<div id="cell-10" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initializing PCA object </span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">5000</span>) <span class="co">#Default params for our case: 2 principal components</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting to our embedded text</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>pca_data <span class="op">=</span> pca.fit_transform(X_tfidf.toarray())</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initializing t-SNE object</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">5000</span>) <span class="co"># Default params for our case: 2 components, perplexity = 30, n_iter = 1000</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting to our embedded text</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>tsne_data <span class="op">=</span> tsne.fit_transform(X_tfidf.toarray())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Plotting Results</strong></p>
<div id="cell-12" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting PCA results</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(pca_data[:, <span class="dv">0</span>], pca_data[:, <span class="dv">1</span>])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"PCA on TF-IDF (Unigrams and Bigrams, n = 2500)"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"PC1"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"PC2"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The above PCA plot demonstrates a very strong linear structure, where most of the data poinrs are concentrated along a single dominant direction. The most likely reason for this is that our princple components analysis was heavily influenced by a small group of dominant features. When thinking about this within the context of our reviews data, it makes sense that there are especially strong features, as reviews are often repetitive and contain a lot of the same content, especially adjectives and in this case names of standard electronics (i.e.&nbsp;batteries, keyboards, storage, etc.)</p>
<div id="cell-14" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting t-SNE results</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(tsne_data[:, <span class="dv">0</span>], tsne_data[:, <span class="dv">1</span>])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"t-SNE on TF-IDF (Unigrams and Bigrams, n = 2500)"</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dim 1"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Dim 2"</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In contrast to our PCA plot, the t-SNE plot above shows a bit more promise. Ignoring the massive circle of points on the outer ring of the plot, we can see that t-SNE is able to better capture localized groups in the data, which makes it more ideal for clustering. Of course, we will have to tune some parameters to get a better result, but this is a strong first step. Going into this first stage, I had a feeling that t-SNE would outperform PCA when collapsing our TF-IDF embeddings.</p>
<p>Moving forward, I will shift my focus toward refining our t-SNE reduction process. Below, I outline a function that I will use to help speed up the process.</p>
</section>
</section>
<section id="parameter-optimization-dimension-reduction" class="level2">
<h2 class="anchored" data-anchor-id="parameter-optimization-dimension-reduction">Parameter Optimization: Dimension Reduction</h2>
<p>Below, I define the following functions:</p>
<ul>
<li><strong><code>plot_embeddings()</code></strong> : A helper function that creates scatterplot of data across dimensions returned by t-SNE</li>
<li><strong><code>reduce_and_visualize()</code></strong>: Our main function that handles parameter adjustment for both t-SNE reduction and TF-IDF embedding. Controls sample size as well for quick iteration</li>
</ul>
<p><strong>Note:</strong> <em>For the <code>plot_embeddings()</code> function, I consulted an LLM to help write the code that produced the parameters table. At the bottom of this page, I provide the original function used to display the plots, as well as a citation that includes my prompt<span class="citation" data-cites="gpt4o_textfunc"><sup><a href="#ref-gpt4o_textfunc" role="doc-biblioref">8</a></sup></span>.</em></p>
<div id="cell-18" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_embeddings(data, title, labels<span class="op">=</span><span class="va">None</span>, params<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This function:</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    1) Creates a scatterplot of t-SNE reduced, TF-IDF embedded text data    </span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">    'data': Our t-SNE output </span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">    'title': name for our plot</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">    'labels': the condition we use to color our points (column in the data set)</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">    'params': is a dictionary that we define in redude_and_visualize() containing all of the parameters that we used</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">              in this function, it is used to plot them in a table next to our visualization.</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initializing figure</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plt.figure(figsize=(10,6))</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>,<span class="dv">6</span>), gridspec_kw<span class="op">=</span>{<span class="st">"width_ratios"</span>: [<span class="dv">3</span>, <span class="dv">1</span>]})</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> ax[<span class="dv">0</span>].scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], <span class="co"># First and second axes produced by t-SNE</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>                          c <span class="op">=</span> labels, <span class="co"># Fill condition (if any)</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>                          cmap <span class="op">=</span> <span class="st">"viridis"</span>, <span class="co"># color scale</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>                          s <span class="op">=</span> <span class="dv">10</span>, <span class="co"># Size of points</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                          alpha <span class="op">=</span> <span class="fl">0.8</span>) <span class="co"># Opacity of points</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(title)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_xlabel(<span class="st">"Dimension 1"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_ylabel(<span class="st">"Dimension 2"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    fig.colorbar(scatter, ax<span class="op">=</span>ax[<span class="dv">0</span>], label <span class="op">=</span> <span class="st">"Rating"</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handling params table</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> params:</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        param_table <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(params.items()), columns<span class="op">=</span>[<span class="st">"PARAMETER"</span>, <span class="st">"VALUE"</span>])</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        ax[<span class="dv">1</span>].axis(<span class="st">"off"</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        table <span class="op">=</span> ax[<span class="dv">1</span>].table(cellText<span class="op">=</span>param_table.values, colLabels<span class="op">=</span>param_table.columns, loc<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        table.auto_set_font_size(<span class="va">False</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        table.set_fontsize(<span class="dv">10</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        table.auto_set_column_width(col<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(param_table.columns))))</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, for our main function <code>reduce_and_visualize()</code>, I use the following parameters</p>
<ul>
<li><strong>reviews:</strong> our pandas dataframe containing the target ‘reviewTextClean’ column</li>
<li><strong>sample_size:</strong> the number of samples we want to take from the dataframe</li>
<li><strong>random_state:</strong> our seed for random processes (sampling and t-SNE)</li>
<li><strong>perplexity:</strong> the perplexity value for our t-SNE process (Outlined above)</li>
<li><strong>n_iter:</strong> Number of iterations for t-SNE</li>
<li><strong>max_features:</strong> maximum number of TF-IDF features</li>
<li><strong>ngram_range</strong> N-gram range for TF-IDF (i.e.&nbsp;(1,1) is unigrams only, (1,2) is both unigrams and bigrams, and (2,2) is only bigrams)</li>
<li><strong>min_df:</strong> Minimum document frequency for TF-IDF</li>
<li><strong>max_df:</strong> Maximum document frequency for TF-IDF</li>
<li><strong>intermediate_pca:</strong> A boolean that states whether or not we use PCA before running t-SNE</li>
<li><strong>return_df:</strong> A boolean that states whether or not we return our collapsed dataframe (Will use this later If we want to keep the results)</li>
<li><strong>show_plot:</strong> A boolean that states whether we show the resulting plot or not.</li>
</ul>
<p>The <a href="https://scikit-learn.org/dev/modules/generated/sklearn.manifold.TSNE.html">scikit-learn documentation on t-SNE</a> highly recommends that we use another form of dimension reduction before running t-SNE to speed up the process of computation. Therefore, in this function I include the <code>intermediate_pca</code> parameter, which allows me to decide whether or not I run principal components analysis on the data before feeding it into t-SNE. The documentation advices that this process should reduce our data to a ‘reasonable’ amount of dimensions<span class="citation" data-cites="scikitTSNE"><sup><a href="#ref-scikitTSNE" role="doc-biblioref">9</a></sup></span>. In this function, I elect to go for 50 principal components. However, in future iterations I intend to optimize this parameter as well. For now, I will keep it static.</p>
<div id="cell-20" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reduce_and_visualize(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>        reviews,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        sample_size<span class="op">=</span><span class="dv">2500</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">5000</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        perplexity<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        n_iter<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        max_features<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        ngram_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">2</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        min_df<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        max_df<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        intermediate_pca<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        return_df <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        show_plot <span class="op">=</span> <span class="va">True</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">    This function:</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co">    1) applies TF-IDF embedding to our text data</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co">    2) (if intermediate_pca = True) runs intermediate PCA with n_components set to 50 </span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co">    3) Takes either raw data or PCA-reduced data and feeds it into t-SNE with set params</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Our first step is to break off our predefined sample data (defined in sample_size)</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sample_size <span class="op">&lt;</span> <span class="bu">len</span>(reviews):</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        sampled_reviews <span class="op">=</span> reviews.sample(n<span class="op">=</span>sample_size, random_state<span class="op">=</span>random_state).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        sampled_reviews <span class="op">=</span> reviews.reset_index(drop<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Next we need to extract the relevant columns</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    review_texts <span class="op">=</span> sampled_reviews[<span class="st">'reviewTextClean'</span>]</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    review_ratings <span class="op">=</span> sampled_reviews[<span class="st">'reviewRating'</span>]</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now we can initialize our TF-IDF object and fit it to our cleaned review text</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    tfidf <span class="op">=</span> TfidfVectorizer(</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        max_features<span class="op">=</span>max_features,</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        ngram_range<span class="op">=</span>ngram_range,</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        min_df<span class="op">=</span>min_df,</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        max_df<span class="op">=</span>max_df,    </span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    X_tfidf <span class="op">=</span> tfidf.fit_transform(review_texts)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Here, we are extracing the most important terms for each observation</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    feature_names <span class="op">=</span> np.array(tfidf.get_feature_names_out())</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    most_important_terms <span class="op">=</span> feature_names[np.argmax(X_tfidf.toarray(), axis<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now, we handle intermediate PCA conditions, converting our sparse matrix into a dense numpy array in both cases using .toarray()</span></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> intermediate_pca:</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Applying intermediate PCA..."</span>)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize PCA object</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>        pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">50</span>, random_state<span class="op">=</span>random_state)</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Applying to X_tfidf</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>        X_reduced <span class="op">=</span> pca.fit_transform(X_tfidf.toarray()) </span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>        X_reduced <span class="op">=</span> X_tfidf.toarray()</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Once that is handled, we can feed our dense array into t-SNE</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Applying t-SNE..."</span>)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span>perplexity, random_state<span class="op">=</span>random_state, n_iter<span class="op">=</span>n_iter) <span class="co"># Here we collapse to 2-Dimensions, but in some cases we may need 3</span></span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>    reduced_data <span class="op">=</span> tsne.fit_transform(X_reduced)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creating a dataframe for later clustering </span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>    reduced_df <span class="op">=</span> pd.DataFrame(reduced_data, columns<span class="op">=</span>[<span class="st">"Dim1"</span>, <span class="st">"Dim2"</span>])</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>    reduced_df[<span class="st">"Rating"</span>] <span class="op">=</span> review_ratings.values</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>    reduced_df[<span class="st">"Most_Important_Term"</span>] <span class="op">=</span> most_important_terms</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gathering our parameters for the plot</span></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Sample Size"</span>: sample_size,</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Perplexity"</span>: perplexity,</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Iterations"</span>: n_iter,</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Max Features"</span>: max_features,</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">"N-gram Range"</span>: ngram_range,</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Min DF"</span>: min_df,</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Max DF"</span>: max_df,</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Intermediate PCA"</span>: intermediate_pca</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_plot:</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># After all of that, we can now plot our results...</span></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Plotting results..."</span>)</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>        plot_embeddings(</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>            reduced_data,</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>            title <span class="op">=</span> <span class="ss">f"t-SNE With TF-IDF Embeddings"</span>,</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> review_ratings,</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>            params <span class="op">=</span> params</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return reduced dataframe</span></span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> return_df:</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> reduced_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="test-1-intermediate-pca" class="level3">
<h3 class="anchored" data-anchor-id="test-1-intermediate-pca">Test 1: Intermediate PCA</h3>
<p>Let’s test out this function with all of the same paremeters as our base case while also including intermediate PCA</p>
<div id="cell-23" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing out this code</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This plot above shows results of our algorithm, when using all of the same parameters as our default case above, with the only difference being the inclusion of intermediate PCA. At a glance, this result seems to drastically improve our standard t-SNE process by a long-shot. The data points are much more spread out, and there are nice clusters beginning to form. The first method was able to extract some local structure, but it also yielded a massive spiral of points around said structure.</p>
<p>Taking this back to the context of our data, we unfortunately see litle to no relationship between cluster groupings and ratings score - meaning that the rating associated with a given review may not be related to the location of the review’s most important word in a high dimensional space. Nonetheless, there are clusters in this data, and the sections below will help us identify what they represent.</p>
</section>
<section id="test-2-no-intermediate-pca" class="level3">
<h3 class="anchored" data-anchor-id="test-2-no-intermediate-pca">Test 2: No Intermediate PCA</h3>
<p>In this test, I will apply all of the same parameters without the use of intermediate PCA. The goal here is to confirm that intermediate PCA was indeed the step that led to better extraction of the local relationships in our text data.</p>
<div id="cell-26" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, intermediate_pca<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-12-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The plot above confirms that intermediate PCA is a critical step in producing useful results when reducing our data</p>
</section>
<section id="test-3-adjusting-perplexity" class="level3">
<h3 class="anchored" data-anchor-id="test-3-adjusting-perplexity">Test 3: Adjusting Perplexity</h3>
<p>In this section, I will apply low and high <code>perplexity</code> parameters to our algorithm, and check performance for both. As a refresher, perplexity controls the size of each data point’s neighborhood. For a more robust explanation, please refer to the <a href="https://opentsne.readthedocs.io/en/latest/parameters.html">openTSNE</a> documentation.</p>
<p><strong>Higher <code>perplexity</code> (100)</strong></p>
<div id="cell-29" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, perplexity<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Lower <code>perplexity</code> (10)</strong></p>
<div id="cell-31" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, perplexity<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-14-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation</strong></p>
<p>The first plot uses standard parameters, with a higher <code>perplexity</code> value of 100. In this plot, the distribution of points is more spread out, with larger clusters than our initial plot where <code>perplexity</code> was set to 30. Increased perplexity is synonymous with increased neighborhood size. Therefore, it makes sense to see more global groupings with fewer local clusters as a result. In the second plot, I lower <code>perplexity</code> from 30 to 10, which results in much tighter and local clusters. In the second case, we are lowering the size of a data point’s neighborhood, wich allows t-SNE to capture more localized groups. In the latter case, there is almost too much emphasis placed on local groups, which may yield more clusters when modeling than what would be appropriate. Therefore, from here I elect to use a value of <code>perplexity</code> that is high enough to maintain global relationships, while not being too high to ignore more nuanced local relationships</p>
</section>
<section id="test-4-adjusting-document-frequency-in-tf-idf-embedding" class="level3">
<h3 class="anchored" data-anchor-id="test-4-adjusting-document-frequency-in-tf-idf-embedding">Test 4: Adjusting Document Frequency in TF-IDF Embedding</h3>
<p>In this section, I will tweak the <code>max_df</code> parameter that applies to our initial TF-IDF embedding. The <code>max_df</code> parameter sets an upper bound on the document frequency calculated for certain terms (both unigrams and bigrams in our case). In other words, lowering the value for <code>max_df</code> will drop the threshold for which terms are dropped based on their document frequency. The rationale behind lowering this value is to ignore terms that are common in our data, which may help to create more well-defined clusters</p>
<p><strong>Lower <code>max_df</code> (0.8)</strong></p>
<div id="cell-34" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, perplexity<span class="op">=</span><span class="dv">100</span>, max_df<span class="op">=</span><span class="fl">0.8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Not much of a change compared to plot above, let’s try an even lower value:</p>
<p><strong>Lower <code>max_df</code> (0.6)</strong></p>
<div id="cell-36" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, perplexity<span class="op">=</span><span class="dv">100</span>, max_df<span class="op">=</span><span class="fl">0.6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-16-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Not much of a change in either case. Let’s move on to tweaking our next parameter: <code>max_features</code></p>
</section>
<section id="test-5-tweaking-number-of-iterations-in-t-sne" class="level3">
<h3 class="anchored" data-anchor-id="test-5-tweaking-number-of-iterations-in-t-sne">Test 5: Tweaking Number of Iterations in t-SNE</h3>
<p>The t-SNE parameter <code>n_iter</code> adjusts the number of iterations that the t-SNE algorithm runs through in order to optimize KL-Divergence<span class="citation" data-cites="scikitTSNE"><sup><a href="#ref-scikitTSNE" role="doc-biblioref">9</a></sup></span>. In this test, I will raise the value of <code>n_iter</code> to increase the number of iterations t-SNE uses when trying to collapse dimensions</p>
<p><strong>Increasing <code>n_iter</code> (2000)</strong></p>
<div id="cell-38" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>reduce_and_visualize(reviews, perplexity<span class="op">=</span><span class="dv">100</span>, n_iter<span class="op">=</span><span class="dv">2000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...
Plotting results...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Again, we don’t see much change compared to plots with less iterations.</p>
</section>
<section id="fine-tuning-perplexity" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-perplexity">Fine-tuning Perplexity</h3>
<p>After all of that, it seems that adjusting our <code>perplexity</code> parameter seems to impact our results the most. Thus, in this section I will test different perplexity values that are all greater than 30 - saving the dataset that yields the most promising results.</p>
<p><strong>Testing Different Perplexity Values</strong></p>
<div id="cell-41" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set values to test</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>perplexities <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">40</span>, <span class="dv">140</span>, <span class="dv">20</span>)]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># [40, 60, 80, 100, 120]</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Looping through values </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">## for value in perplexities:</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">##     print(f"PERPLEXITY VALUE: {value}")</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">##     reduce_and_visualize(reviews, perplexity=value)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the sake of saving space, I omit the resulting plots from this process. In short, this loop yielded more dispersion between points as our perplexity parameter increased. When looking at the results for each, the plot corresponding to a <code>perplexity</code> of 100 provided the best balance between global and local groups.</p>
<p>Having said all of that, the dataset that I will use for clustering comes from the following configuration from the <code>reduce_and_visualize</code> function:</p>
<ul>
<li>Perplexity: 100</li>
<li>Iterations: 1000</li>
<li>Max Features: 500</li>
<li>N-gram Range: (1,2) (Unigrams and Bigrams)</li>
<li>Minimum Document Freq: 1</li>
<li>Maximum Document Freq: 1.0</li>
<li>Intermediate PCA: True (n_components = 50)</li>
</ul>
<p>For the sake of clustering speed, I will use a sample of 10,000 rows taken from reviews.</p>
<div id="cell-43" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gathering our dataset </span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>reduced_df <span class="op">=</span> reduce_and_visualize(reviews, sample_size<span class="op">=</span><span class="dv">10000</span>, perplexity<span class="op">=</span><span class="dv">100</span>, show_plot<span class="op">=</span><span class="va">False</span>, return_df<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing first rows</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>reduced_df.head(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Applying intermediate PCA...
Applying t-SNE...</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Dim1</th>
<th data-quarto-table-cell-role="th">Dim2</th>
<th data-quarto-table-cell-role="th">Rating</th>
<th data-quarto-table-cell-role="th">Most_Important_Term</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-15.568591</td>
<td>25.8913</td>
<td>1.0</td>
<td>charger</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="clustering-1" class="level2">
<h2 class="anchored" data-anchor-id="clustering-1">Clustering</h2>
<section id="kmeans-clustering" class="level3">
<h3 class="anchored" data-anchor-id="kmeans-clustering">KMeans Clustering</h3>
<p><strong>Elbow Method (inertia) and Silhouette Score</strong></p>
<p>In case you are unfamiliar, “inertia” measures the squared cumulative distance of each data point to its respective cluster. For example, a lower value for inertia represents tighter clusters (or lower intracluster distances)<span class="citation" data-cites="inertia"><sup><a href="#ref-inertia" role="doc-biblioref">10</a></sup></span>. When selecting an optimal number of clusters based on inertia, it is important to select the lowest number of clusters for which inertia is most drastically reduced. The reason being that inertia will continue to decrease as we add more clusters. This is precisely why we refer to this process as the “Elbow Method,” as we are selecting a number of clusters <span class="math inline">\(k\)</span> where the marginal reduction of inertia by adding another cluster begins to tend towards zero.</p>
<p><span class="math display">\[
\text{Inertia} \ = \sum_{i=1}^{k} \sum_{i \in C_{i}} ||x - \mu_{i}||^2
\]</span></p>
<p>Source: <a href="https://medium.com/@jeffzyme/understanding-inertia-distortion-and-silhouette-scores-and-their-differences-key-metrics-for-458fe28ce2aa">Medium</a></p>
<p>On the other hand, the silhouette score measures how similar a data point is to its own cluster in comparison to other clusters. The value of this metric falls in the range [-1, 1], where high values represent well-matched data points and low-values represent poorly-matched ones<span class="citation" data-cites="inertia"><sup><a href="#ref-inertia" role="doc-biblioref">10</a></sup></span>.</p>
<ul>
<li>Where <span class="math inline">\(a\)</span> is the mean distance between a sample and all other points in the same cluster</li>
<li>and <span class="math inline">\(b\)</span> is the mean distance between a sample and all other points in the nearest cluster</li>
</ul>
<p><span class="math display">\[
\text{Silhouette} \ = \frac{b - a}{max(a,b)}
\]</span></p>
<p>Source: <a href="https://napsterinblue.github.io/notes/machine_learning/unsupervised/advanced_silhouettes/">Napsterinblue</a> via Github</p>
<div id="cell-45" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a range of clusters to test</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>k_clusters <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">30</span>)]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize inertia and silhouette score lists for tracking</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>inertia <span class="op">=</span> []</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>silhouette_avg <span class="op">=</span> []</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over different cluster numbers</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_clusters:</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize KMeans object for each one</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fitting to data</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Appending inertia value to list</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    inertia.append(kmeans.inertia_)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Computing silhouette score</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    silhouette_avg.append(silhouette_score(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]], kmeans.labels_))</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting elbow method </span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>plt.plot(k_clusters, inertia, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Elbow Method for Optimal # of Clusters"</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of Clusters (k)"</span>)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Inertia"</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting silhouette scores</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>plt.plot(k_clusters, silhouette_avg, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhouette Score for Optimal # of Clusters'</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-20-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Elbow Plot (Inertia)</strong></p>
<ul>
<li>The elbow plot above shows us that the optimal number or clusters is around 6, as a continued increase in the number of clusters beyond this point reduces inertia by a smaller amount each time.</li>
</ul>
<p><strong>Silhouette Score</strong></p>
<ul>
<li>Unlike the elbow plot, our silhouette scores show that the optimal number of clusters in the data may be far larger (around 20-25 if we do not want to overallocate).</li>
</ul>
<p><strong>Combined Interpretation</strong></p>
<ul>
<li>When taking both of these results into consideration, I will elect to choose a number of clusters that falls on the higher side. The reason being that our visualizations of the dataset in the sections above show that there are far more than 6 clusters present in our data. Therefore, I am going to run the algorithm with 10,15,20, and 25 clusters. In the end, I will plot the results and see which of these configurations performs the best.</li>
</ul>
<div id="cell-47" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Running KMeans with optimal # of clusters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>possible_ks <span class="op">=</span> [<span class="dv">10</span>,<span class="dv">15</span>,<span class="dv">20</span>,<span class="dv">25</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> possible_ks:</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    reduced_df[<span class="ss">f"KMeans_</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">_Clusters"</span>] <span class="op">=</span> kmeans.fit_predict(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>reduced_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Dim1</th>
<th data-quarto-table-cell-role="th">Dim2</th>
<th data-quarto-table-cell-role="th">Rating</th>
<th data-quarto-table-cell-role="th">Most_Important_Term</th>
<th data-quarto-table-cell-role="th">KMeans_10_Clusters</th>
<th data-quarto-table-cell-role="th">KMeans_15_Clusters</th>
<th data-quarto-table-cell-role="th">KMeans_20_Clusters</th>
<th data-quarto-table-cell-role="th">KMeans_25_Clusters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-15.568591</td>
<td>25.891300</td>
<td>1.0</td>
<td>charger</td>
<td>2</td>
<td>13</td>
<td>18</td>
<td>24</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>49.179565</td>
<td>-5.040786</td>
<td>5.0</td>
<td>replacement</td>
<td>0</td>
<td>12</td>
<td>12</td>
<td>16</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>35.679398</td>
<td>-12.378240</td>
<td>5.0</td>
<td>ive</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.708546</td>
<td>39.718727</td>
<td>5.0</td>
<td>little</td>
<td>9</td>
<td>9</td>
<td>9</td>
<td>19</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-50.714245</td>
<td>-1.021938</td>
<td>5.0</td>
<td>fits</td>
<td>8</td>
<td>8</td>
<td>16</td>
<td>12</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="hierarchical-agglomerative-clustering" class="level2">
<h2 class="anchored" data-anchor-id="hierarchical-agglomerative-clustering">Hierarchical (Agglomerative) Clustering</h2>
<p><strong>Silhouette Score</strong></p>
<p>Similar to KMeans, we will optimize the number of clusters <span class="math inline">\(k\)</span> in our hierarchical clustering model using the silhouette score.</p>
<div id="cell-50" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Silhouette Score list</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>silhouette_avg <span class="op">=</span> []</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over different clusters</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_clusters:</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># initializing agglomerative clutering object</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    agglo <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span>k)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pulling cluster labels</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    cluster_labels <span class="op">=</span> agglo.fit_predict(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append silhouette score to list</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    silhouette_avg.append(silhouette_score(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]], cluster_labels))</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot silhouette scores </span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>plt.plot(k_clusters, silhouette_avg, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Silhouette Score for Optimal # of Clusters'</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="main_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Looking at the above silhouette score plot for agglomerative clustering with different numbers of centroids, We see a point on the plot where the silhouette score begins to decrease around 22 clusters before increasing again. Taking this into account, I am only going to run one version of the hierarchical clustering model, where I set <span class="math inline">\(k\)</span> equal to 22:</p>
<div id="cell-52" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>optimal_k_agglo <span class="op">=</span> <span class="dv">22</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>agglo <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span>optimal_k_agglo)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>reduced_df[<span class="st">'Agglo_22_Clusters'</span>] <span class="op">=</span> agglo.fit_predict(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="dbscan" class="level2">
<h2 class="anchored" data-anchor-id="dbscan">DBSCAN</h2>
<p>DBCAN requires the parameters <code>eps</code> - or the maximum distance between two samples for them to be considered in the same neighborhood, and <code>min_samples</code> - or the number of samples in a neighborhood for a point to be considered the “core” point<span class="citation" data-cites="eps"><sup><a href="#ref-eps" role="doc-biblioref">7</a></sup></span>. Below, I will optimize each of these parameters using a set of potential</p>
<p><strong>Optimizing DBSCAN Hyperparams</strong></p>
<div id="cell-54" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initializing list of potential eps and min_sample values </span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>eps_values <span class="op">=</span> [<span class="fl">0.1</span>,<span class="fl">0.15</span>,<span class="fl">0.2</span>,<span class="fl">0.25</span>,<span class="fl">0.3</span>,<span class="fl">0.35</span>,<span class="fl">0.4</span>,<span class="fl">0.45</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.7</span>,<span class="fl">0.8</span>]</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>min_sample_values <span class="op">=</span> [<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize starting value for best silhouette score, eps, and min_sample values</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>best_silhouette <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>best_eps <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>best_min_sample <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop over different eps and min_sample values</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> eps <span class="kw">in</span> eps_values:</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> min_sample <span class="kw">in</span> min_sample_values:</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize DBSCAN object</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> DBSCAN(eps<span class="op">=</span>eps, min_samples<span class="op">=</span>min_sample)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit DBSCAN to the data and predict cluster labels (-1 indicates noise)</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        cluster_labels <span class="op">=</span> db.fit_predict(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if DBSCAN formed more than one cluster (ignore cases with only noise or one cluster)</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="bu">set</span>(cluster_labels)) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate silhouette score</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            silhouette_avg_db <span class="op">=</span> silhouette_score(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]], cluster_labels)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update best params if the current silhouette score is higher than the best one so far</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> silhouette_avg_db <span class="op">&gt;</span> best_silhouette:</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>                best_silhouette <span class="op">=</span> silhouette_avg_db</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>                best_eps <span class="op">=</span> eps</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>                best_min_sample <span class="op">=</span> min_sample</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"OPTIMAL DBSCAN PARAMS: eps=</span><span class="sc">{</span>best_eps<span class="sc">}</span><span class="ss">, min_samples=</span><span class="sc">{</span>best_min_sample<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL DBSCAN PARAMS: eps=0.6, min_samples=3</code></pre>
</div>
</div>
<p>After running a quick optimization on our parameters, we can see that the best values are 0.6 for <code>eps</code> and 3 for <code>min_samples</code>. Let’s now use these parameters to run DBSCAN cluster assignments that we can plot later on.</p>
<div id="cell-56" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Running DBSCAN with optimal Params</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span>best_eps, min_samples<span class="op">=</span>best_min_sample)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>reduced_df[<span class="st">'DBSCAN_Cluster'</span>] <span class="op">=</span> db.fit_predict(reduced_df[[<span class="st">'Dim1'</span>, <span class="st">'Dim2'</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="plotting-clustering-results" class="level2">
<h2 class="anchored" data-anchor-id="plotting-clustering-results">Plotting Clustering Results</h2>
<section id="kmeans" class="level3">
<h3 class="anchored" data-anchor-id="kmeans">Kmeans</h3>
<p>The results for KMeans looks promising! Unfortunately, the web development software that I am working with won’t let me display interactive plots, so I took the liberty of posting some screenshots of my results below. In each of these screenshots, you can see where I highlight a certain point in different clusters. In the first case, the data point that I hover over has “camera” as its most important word. Interestingly, most of the other points in this cluster also contain other contextually-related words to “camera”, like “lenses”, “picture”, and “tripod”.</p>
<p>Similarly, in the second image, I hover over a point in a different cluster in which the most important term is “excellent”. Unlike the previous cluster, this one contains words that convey emotion and description, like “awesome” and “highly recommend”.</p>
<p>In the third image, I move to a different cluster and hover over a point where the most important term is “TV”. Like our first example, this cluster contains many terms related to “TV”, like “sony”, “antenna”, “cable”, and “mount”. Unfortunately, this process was not completely immune to error. There are several cases where clusters all contain a single word (e.g.&nbsp;every point in the top purple cluster has “good” as its most important term). In the future, I will try to correct these mistakes by using more sophisticated embedding techniques like <a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert"><code>BERT</code></a>.</p>
<div id="cell-58" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interactive plot for k_means</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># KMeans Plotly Plot</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>fig_kmeans <span class="op">=</span> px.scatter(reduced_df, x<span class="op">=</span><span class="st">'Dim1'</span>, y<span class="op">=</span><span class="st">'Dim2'</span>, color<span class="op">=</span><span class="st">'KMeans_25_Clusters'</span>,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>                        hover_data<span class="op">=</span>[<span class="st">'Rating'</span>, <span class="st">'Most_Important_Term'</span>], title<span class="op">=</span><span class="st">"KMeans Clustering (k = 25)"</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>fig_kmeans.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Fig 1: KMeans Clustering - The Camera Cluster</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/kmeans_interactive/KMeans_camera.png" class="img-fluid" width="800"></p>
<p><strong>Fig 2: KMeans Clustering - The Emotions &amp; Descriptor Cluster</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/kmeans_interactive/KMeans_happy.png" class="img-fluid" width="800"></p>
<p><strong>Fig 3: KMeans Clustering - The TV Cluster</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/kmeans_interactive/KMeans_tv.png" class="img-fluid" width="800"></p>
</section>
</section>
<section id="hierarchical-clustering-1" class="level2">
<h2 class="anchored" data-anchor-id="hierarchical-clustering-1">Hierarchical Clustering</h2>
<p>Similar to KMeans, hierarchical clustering performed well when applied to our dimension-reduced data. In the first example below, you can see a point on the plot where its most important term is “speakers”. The other points in this cluster also share contextually-similar terms like “sound”, “wireless”, “ear”, “headphones”, and “music”.</p>
<p>In the second plot, we see a point in another cluster whose most important term is “harddrive”. Once again, we observe an interesting pattern within its neighboring points, whose most important terms include words like “data”, “gb”, “files”, and “ssd”.</p>
<p>Finally, similar to the KMeans results, we again observe flaws in the clustering results. In the third image, I provide a screenshot of what I call “the good cluster”, in which every data point’s most important term is “good”. This cluster was picked up by both the KMeans, and hierarchical models - which further reinforces the need to conduct more robust preprocessing in the future.</p>
<div id="cell-61" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Agglomerative Plotly Plot</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>fig_agglo <span class="op">=</span> px.scatter(reduced_df, x<span class="op">=</span><span class="st">'Dim1'</span>, y<span class="op">=</span><span class="st">'Dim2'</span>, color<span class="op">=</span><span class="st">'Agglo_22_Clusters'</span>, </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                       hover_data<span class="op">=</span>[<span class="st">'Rating'</span>, <span class="st">'Most_Important_Term'</span>], title<span class="op">=</span><span class="st">"Hierarchical Clustering (k = 22)"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>fig_agglo.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Fig 1: Hierarchical Clustering - The Music/Sound Device Cluster</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/agglo_interactive/agglo_speakers.png" class="img-fluid" width="800"></p>
<p><strong>Fig 2: Hierarchical Clustering - The Data Storage Cluster</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/agglo_interactive/agglo_harddrive.png" class="img-fluid" width="800"></p>
<p><strong>Fig 3 Hierarchical Clustering - “The Good Cluster”:</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/agglo_interactive/agglo_good.png" class="img-fluid" width="800"></p>
</section>
<section id="dbscan-1" class="level2">
<h2 class="anchored" data-anchor-id="dbscan-1">DBSCAN</h2>
<p>In the beginning of this page, I predicted that DBSCAN would outperform the other two clustering methods. Unfortunately, the results I obtained using DBSCAN are rather underwhelming. There is pretty much zero separation between the over 600 clusters. The data points are scattered, with no clear structure or meaningful differentiation between the clusters. Upon further reflection, I believe the issue stems from not optimizing the <code>eps</code> and <code>min_samples</code> hyperparameters effectively. DBSCAN’s reliance on these parameters makes it sensitive to how they are set, and any miscalibration can result in an over-segmentation of the data or a failure to detect meaningful clusters. While this plot is pretty to look at, the clusters don’t provide any real context into the structure of the data points. In the future, I plan to revisit the parameter optimization above with hopes to improve this model’s performace, but for now, I leave you with this storm cloud of data.</p>
<div id="cell-64" class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DBSCAN Plotly Plot</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>fig_dbscan <span class="op">=</span> px.scatter(reduced_df, x<span class="op">=</span><span class="st">'Dim1'</span>, y<span class="op">=</span><span class="st">'Dim2'</span>, color<span class="op">=</span><span class="st">'DBSCAN_Cluster'</span>, </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                        hover_data<span class="op">=</span>[<span class="st">'Rating'</span>, <span class="st">'Most_Important_Term'</span>], title<span class="op">=</span><span class="st">"DBSCAN Clustering"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>fig_dbscan.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Fig 1: DBSCAN Results</strong></p>
<p><img src="../../xtra/multiclass-portfolio-website/images/DBSCAN_clustering_results.png" class="img-fluid" width="800"></p>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>In this section, I start off by performing two different dimension reduction methods on my TF-IDF embedded review text data. In both cases (<strong>PCA</strong> and <strong>t-SNE</strong>) I used their default parameters. After running the two baseline reduction techniques, I plotted the results of each, and discovered that PCA’s linear reduction fell short in collapsing our text data into a meaningful representation. On the other hand, t-SNE showed promise with its ability to capture local groups in the data. However, the baseline function had to be refined in order to produce more meaningful results.</p>
<p>In the next section, refined the dimension reduction process by building a custom function that performec TF-IDF and t-SNE using custom preset parameters. From there, I tweaked a few different function parameters until I arrived at a configuration that I liked. After saving the best configuration’s result to the dataset <code>reduced_df</code>, I went ahead with clustering. For KMeans clustering, I optimized the <code>n_clusters</code> hyperparameter using the Elbow Method and Silhouette scores. For hierarchical clustering, I optimized using only silhouette scores. Finally, for DBSCAN, I optimized silhouette scores by using a grid search approach where I tried different combinations of the hyperparameters <code>eps</code> and <code>min_samples</code>, continuously updating their best values each time a higher silhouette score was found.</p>
<p>When looking at results from my clustering of Amazon Electronics reviews, I can say with relative confidence that the different regions/clusters in the text data do not have any real influence on review score. Instead, it’s more likely that each cluster relates to a different type of electronic good or subcategory like I mention above. Moving forward, I am not sure if these cluster assignments will be of any use when we try supervised learning.</p>
<section id="challenges" class="level2">
<h2 class="anchored" data-anchor-id="challenges">Challenges</h2>
<p><span style="text-decoration: underline;"><strong>Plotting Parameters Table</strong></span></p>
<p>As I outlined above, I had to leverage the help of OpenAI’s GPT-4o<span class="citation" data-cites="gpt4o_tablefunc"><sup><a href="#ref-gpt4o_tablefunc" role="doc-biblioref">11</a></sup></span> model to assist in writing code that produces a side table containing the parameters used in the <code>reduce_and_visualize()</code> function. Here is the original function that I pasted into that prompt:</p>
<pre><code>def plot_embeddings(data, title, labels=None):
    """
    This function creates a scatterplot of t-SNE reduced, TF-IDF embedded text data

    'data': np.array object (2D). contains our t-SNE output 
    'title': the name for our plot
    'labels': the condition we use to color our points (column in the data set)
    """
    plt.figure(figsize=(12, 6))
    scatter = plt.scatter(data[:, 0], data[:, 1], c=labels, cmap="viridis", s=10, alpha=0.7)
    plt.colorbar(scatter, label="Rating")
    plt.title(title)
    plt.xlabel("Dim 1")
    plt.ylabel("Dim 2")
    plt.show()</code></pre>
<p><span style="text-decoration: underline;"><strong>DBSCAN Problems</strong></span></p>
<p>It is highly likely (even after processing) that my <code>reviewTextClean</code> column may typos, informal language, or otherwise irrelevant content that may impede model performance down the line.</p>
</section>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section"></h2>
<p><strong>Next Section: <a href="../../technical-details/supervised-learning/main.html">Supervised Learning</a></strong></p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-EigenPCA" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><a href="https://medium.com/@dareyadewumi650/understanding-the-role-of-eigenvectors-and-eigenvalues-in-pca-dimensionality-reduction-10186dad0c5c">Understanding the role of eigenvectors and eigenvalues in PCA dimensionality reduction.</a></div>
</div>
<div id="ref-WikiTSNE" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">T-distributed stochastic neighbor embedding</a>.</div>
</div>
<div id="ref-WikiKL" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback leibler divergence</a>.</div>
</div>
<div id="ref-perplexity" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><a href="https://opentsne.readthedocs.io/en/latest/index.html">openTSNE</a>.</div>
</div>
<div id="ref-eucdistance" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><a href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean distance</a>.</div>
</div>
<div id="ref-Week8Slides" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><a href="https://jjacobs.me/dsan5000/5a969ccadf5ebc7ab4027c0706d0a1dbc7be7117/w08/#k-means-clustering">DSAN 5000: Week 8 - unsupervised learning</a>.</div>
</div>
<div id="ref-eps" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><a href="https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/">DBSCAN clustering in ML | density based clustering</a>.</div>
</div>
<div id="ref-gpt4o_textfunc" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">‘Prompt: How can i optimize the execution speed of this function [pasted]?‘ ChatGPT, version-4o, OpenAI, dec-7, 2024, chat.openai.com.</div>
</div>
<div id="ref-scikitTSNE" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><a href="https://scikit-learn.org/dev/modules/generated/sklearn.manifold.TSNE.html">Scikit-learn TSNE documentation</a>.</div>
</div>
<div id="ref-inertia" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><a href="https://victorleungtw.com/2023/12/16/inertia/">Understanding inertia and silhouette coefficient - key metrics in clustering analysis</a>.</div>
</div>
<div id="ref-gpt4o_tablefunc" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><span>“Prompt: Using a dictionary called ’params”</span> that contains the parameters used in my function reduce_and_visualize(), can you add a table containing said params to this plotting function [pasted]?‘ ChatGPT, version-4o, OpenAI, dec-11, 2024, chat.openai.com.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>