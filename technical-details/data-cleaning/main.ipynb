{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this section, I continue by cleaning the data gathered in the [Data Collection](../data-collection/main.ipynb) section. To begin, I load in the raw data file from the `data/raw-data/` directory. From there, I drop columns that are not relevant to my [EDA](../eda/main.ipynb) and modeling down the line. Throughout this section, I try to consistently reduce the number of NA values until none remain in the final version of the dataset. While cleaning, I also make sure to drop NA values from rows where their removal wouldn't seriously impact the size of the dataset. The columns that ended up matching this criteria were `reviewerName` and `summary`. I also make sure to assign proper data types to the columns - changing number of community votes `vote` to an integer value, date of review posting `reviewTime` to datetime. Finally, I run the function `clean_review()` on the `reviewText` and `summary` columns. In the challenges section, I highlight the computational bottleneck faced when trying to run `clean_text()` on over 12 million entries, and how I improved its performance. The final result of this section yields a clean dataset, ripe for further exploration and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code \n",
    "\n",
    "### Importing Packages\n",
    "\n",
    "First, let's import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import gzip # For unzipping the raw data\n",
    "import pandas as pd # Using pandas for easier data manipulation\n",
    "import nltk # Using nltk for its list of stopwords\n",
    "import string # string.punctuation will be used for text cleaning\n",
    "\n",
    "import warnings # Turning off warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') #ignoring warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading raw data\n",
    "\n",
    "Now we can load in the processed CSV we constructed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>D. C. Carrad</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "      <td>937612800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime     reviewerID        asin  \\\n",
       "0      5.0   67      True  09 18, 1999  AAP7PPBU72QFM  0151004714   \n",
       "\n",
       "                       style  reviewerName  \\\n",
       "0  {'Format:': ' Hardcover'}  D. C. Carrad   \n",
       "\n",
       "                                          reviewText         summary  \\\n",
       "0  This is the best novel I have read in 2 or 3 y...  A star is born   \n",
       "\n",
       "   unixReviewTime image  \n",
       "0       937612800   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pathway to raw data\n",
    "data_path = \"../../data/raw-data/book_reviews.csv.gz\"\n",
    "\n",
    "# Unzip the CSV file\n",
    "with gzip.open(data_path, 'rb') as f:\n",
    "    # Read the CSV file into a dataframe\n",
    "    reviews_raw = pd.read_csv(f)\n",
    "\n",
    "# Display the first few lines\n",
    "reviews_raw.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our first look at the raw dataframe - we can observe 12 columns containing the following variables:\n",
    "\n",
    "- `overall`: Rating \n",
    "- `vote`: Amount of community votes given to the review. Users will often vote when they find a review helpful\n",
    "- `verified`: Boolean variable that indicates whether an account is verified or not\n",
    "- `reviewTime`: Time of the review (raw)\n",
    "- `reviewerID`: ID of the reviewer\n",
    "- `asin`: Id of the product\n",
    "- `style`: Key-value object. In this case, it describes the format of the book (e.g. Paperback, Hardcover, Kindle, etc.)\n",
    "- `reviewerName`: Name of the reviewer\n",
    "- `reviewText`: Raw, unprocessed text contents of the review\n",
    "- `summary`: The title of the user's review\n",
    "- `unixReviewTime`: Time of the review in unix time (Measures time \"based by the number of non-leap seconds that have elapsed since 00:00:00 UTC\")[@UnixTime].\n",
    "- `image`: Image path (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary Columns\n",
    "\n",
    "First, lets drop the `unixReviewTime`, `style` and `image` columns, since they will not be used in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['overall', 'vote', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
      "       'reviewerName', 'reviewText', 'summary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# list of columns to drop\n",
    "drop_cols = ['unixReviewTime', 'image', 'style']\n",
    "\n",
    "# dropping columns\n",
    "reviews_raw = reviews_raw.drop(columns=drop_cols)\n",
    "\n",
    "# ensuring correct columns were dropped\n",
    "print(reviews_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for missing values\n",
    "\n",
    "Now lets check to see if our dataset contains any NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall               0\n",
      "vote            5790916\n",
      "verified              0\n",
      "reviewTime            0\n",
      "reviewerID            0\n",
      "asin                  0\n",
      "reviewerName       1472\n",
      "reviewText         1640\n",
      "summary             875\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(reviews_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our most important column, `reviewText`, has 1640 null values, so let's get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NULL values in reviewText Column: 0\n"
     ]
    }
   ],
   "source": [
    "# Taking only rows or reviews_raw where reviewText is not null\n",
    "reviews_raw = reviews_raw[reviews_raw['reviewText'].notna()]\n",
    "\n",
    "# Lets make sure this works\n",
    "print(f\"Number of NULL values in reviewText Column: {reviews_raw['reviewText'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data types\n",
    "\n",
    "Before moving forward, let's ensure that each of our column data types are appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall         float64\n",
      "vote             object\n",
      "verified           bool\n",
      "reviewTime       object\n",
      "reviewerID       object\n",
      "asin             object\n",
      "reviewerName     object\n",
      "reviewText       object\n",
      "summary          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(reviews_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make the following changes:\n",
    "\n",
    "- Convert `vote` to an int object, where NA values are replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote column data type: int64\n",
      "Number of NULL values in vote Column: 0\n"
     ]
    }
   ],
   "source": [
    "# Converting 'vote' to integer, while dropping columns from strings and replacing NA with 0 \n",
    "reviews_raw['vote'] = reviews_raw['vote'].replace({',': ''}, regex=True).fillna(0).astype(int)\n",
    "\n",
    "print(f\"Vote column data type: {reviews_raw['vote'].dtype}\")\n",
    "print(f\"Number of NULL values in vote Column: {reviews_raw['vote'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take another look at our null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall            0\n",
      "vote               0\n",
      "verified           0\n",
      "reviewTime         0\n",
      "reviewerID         0\n",
      "asin               0\n",
      "reviewerName    1468\n",
      "reviewText         0\n",
      "summary          787\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(reviews_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step to getting rid of all Null values, lets drop instances where `reviewerName` and `summary` are Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall         0\n",
      "vote            0\n",
      "verified        0\n",
      "reviewTime      0\n",
      "reviewerID      0\n",
      "asin            0\n",
      "reviewerName    0\n",
      "reviewText      0\n",
      "summary         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Taking only rows or reviewerName is not null\n",
    "reviews_raw = reviews_raw[reviews_raw['reviewerName'].notna()]\n",
    "# Now doing the same for the summary column\n",
    "reviews_raw = reviews_raw[reviews_raw['summary'].notna()]\n",
    "\n",
    "# Finally, lets print our null report\n",
    "print(reviews_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we are left with no more NA entries in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "\n",
    "Before moving on to cleaning our actual text data, let's rename `overall` to `reviewRating` and `asin` to `productID` for easier intuition and more uniformity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>productID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>09 18, 1999</td>\n",
       "      <td>AAP7PPBU72QFM</td>\n",
       "      <td>0151004714</td>\n",
       "      <td>D. C. Carrad</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewRating  vote  verified   reviewTime     reviewerID   productID  \\\n",
       "0           5.0    67      True  09 18, 1999  AAP7PPBU72QFM  0151004714   \n",
       "\n",
       "   reviewerName                                         reviewText  \\\n",
       "0  D. C. Carrad  This is the best novel I have read in 2 or 3 y...   \n",
       "\n",
       "          summary  \n",
       "0  A star is born  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming cols\n",
    "reviews_raw.rename(columns={\n",
    "    'overall': 'reviewRating',\n",
    "    'asin': 'productID'\n",
    "}, inplace=True)\n",
    "\n",
    "# printing result\n",
    "reviews_raw.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step before cleaning the text, let's convert `reviewTime` to actual datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of reviewTime column: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Converting reviewTime from object to datetime\n",
    "reviews_raw['reviewTime'] = pd.to_datetime(reviews_raw['reviewTime'], format='%m %d, %Y', errors = 'coerce')\n",
    "\n",
    "# Ensuring this worked\n",
    "print(f\"Data type of reviewTime column: {reviews_raw['reviewTime'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Processing Text Data\n",
    "\n",
    "In this section I will begin to process the text columns within this dataset. I will first remove digits from the text using python's built-in `.isdigit()` function. Next, I will utilize python's `string` library to create a list of punctuation marks that will be referenced when removing all punctuation from the text. Step three involves lowercasing the text using python's built-in `.lower()` function. Finally I will remove stopwords in the text with the help of `nltk.corpus`. If you are not familiar, stopwords are terms that do not carry any semantic meaning - some examples include 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', etc. From there. After all of this is complete, we will have a fully cleaned dataframe that is ready for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORDS\n",
      "=============\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# importing stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "print(\"STOP WORDS\")\n",
    "print(\"=============\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUNCTUATION MARKS\n",
      "===================\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# Gathering punctuation marks to be removed\n",
    "punctuation_marks = list(string.punctuation)\n",
    "\n",
    "print(\"PUNCTUATION MARKS\")\n",
    "print(\"===================\")\n",
    "print(punctuation_marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I define the function `clean_review()` which takes a string as an input and applies all of the asjustments above in the following order:\n",
    "\n",
    "1. Removes digits using `.isdigit()`\n",
    "2. Removes puncuation marks by referencing the list object `punctuation_marks`\n",
    "3. Lowercases the text using python's in-built `.lower()`\n",
    "4. Removes stopwords using list object `stop_words`\n",
    "\n",
    "***Note***: The function[@gpt4o_textfunc] used below was provided to me by OpenAI's GPT-4o model. The full citation can be found at the bottom of the page. Additionally, my original function will be included in the **Challenges** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def clean_review(text):\n",
      "    # Predefine allowed characters (alphabet and space)\n",
      "    allowed_chars = set('abcdefghijklmnopqrstuvwxyz ')\n",
      "    \n",
      "    # Dropping digits and punctuation while lowercasing\n",
      "    text = ''.join(char.lower() for char in text if char.lower() in allowed_chars)\n",
      "    \n",
      "    # Splitting and removing stopwords\n",
      "    words = text.split()\n",
      "    cleaned_words = [word for word in words if word not in stop_words]\n",
      "\n",
      "    # Return the cleaned text\n",
      "    return ' '.join(cleaned_words)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_review(text):\n",
    "    # Predefine allowed characters (alphabet and space)\n",
    "    allowed_chars = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "    \n",
    "    # Dropping digits and punctuation while lowercasing\n",
    "    text = ''.join(char.lower() for char in text if char.lower() in allowed_chars)\n",
    "    \n",
    "    # Splitting and removing stopwords\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Return the cleaned text\n",
    "    return ' '.join(cleaned_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will apply the function above to the `reviewText` and `summary` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTextClean</th>\n",
       "      <th>summaryClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best novel read years everything fiction beaut...</td>\n",
       "      <td>star born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pages pages introspection style writers like h...</td>\n",
       "      <td>stream consciousness novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kind novel read time lose book days possibly w...</td>\n",
       "      <td>im huge fan author one disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gorgeous language incredible writer last life ...</td>\n",
       "      <td>beautiful book ever read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taken reviews compared book leopard promised b...</td>\n",
       "      <td>dissenting viewin part</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     reviewTextClean  \\\n",
       "0  best novel read years everything fiction beaut...   \n",
       "1  pages pages introspection style writers like h...   \n",
       "2  kind novel read time lose book days possibly w...   \n",
       "3  gorgeous language incredible writer last life ...   \n",
       "4  taken reviews compared book leopard promised b...   \n",
       "\n",
       "                        summaryClean  \n",
       "0                          star born  \n",
       "1         stream consciousness novel  \n",
       "2  im huge fan author one disappoint  \n",
       "3           beautiful book ever read  \n",
       "4             dissenting viewin part  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews_raw['reviewTextClean'] = reviews_raw['reviewText'].apply(clean_review)\n",
    "# reviews_raw['summaryClean'] = reviews_raw['summary'].apply(clean_review)\n",
    "\n",
    "reviews_raw[['reviewTextClean', 'summaryClean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first few rows of cleaned text. It looks like everything works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "- Experienced serious bottlenecks with string-based text cleaning, so I asked chat-gpt to optimize it for me. You can find the citation below. Additionally, here is the original function that I fed into the LLM:\n",
    "\n",
    "```\n",
    "def clean_review(text):\n",
    "    #Remove digits\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "    #Remove Punctuation\n",
    "    text = ''.join(char for char in text if char not in punctuation_list)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Return cleaned text\n",
    "    return ' '.join(words)\n",
    "```\n",
    "\n",
    "\n",
    "- Due to the massive size of the data, I could only save a trunacted version of the cleaned data set to the `data/processed-data/` directory. Doing this made pushing the data to github easier, while also providing graders with a reference to what the whole dataset looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
