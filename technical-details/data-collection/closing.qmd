# Summary

In this section, I loaded in raw JSON data form containing a corpus of over 6 million Amazon product reviews under the 'Electronics' category. Using custom functions defined in the dataset's source repository, I parsed the data and passed it into a pandas dataframe. As a final step, I zipped the file and moved it into the `data/raw-data/` directory.

## Challenges

[**Memory and Processing Bottlenecks**]{style="text-decoration: underline;"}

Due to the massive size of the raw data file, I had to try a bunch of new methods to successfully load it in. In the end, I elected to use a refined version of the `json` package called [`orjson`](https://github.com/ijl/orjson). Where `json` is the base python library for working with JSON formatted files, `orjson` is a third-party library built in Rust, and optimized for procedures that require rapid serialization of large-scale JSON files.

##

**Next Section: [Data Cleaning](../data-cleaning/main.ipynb)**