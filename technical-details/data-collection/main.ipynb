{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Collection\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{{< include overview.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include methods.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source Information\n",
    "\n",
    "The data from this project is open source and available via a github repository. A very big thank you to the repo owner, [Jianmo Ni](https://x.com/jianmo_ni), who is a former UCSD student that compiled over 233.1 million amazon reviews for their paper on recommendation systems[@DataArticle]. \n",
    "\n",
    "The repo owner offers this data to the public under one condition - that anyone who uses it cites their original work, which I have included in the references section below. Alternatively, this [link](https://cseweb.ucsd.edu/~jmcauley/pdfs/emnlp19a.pdf) will take you directly to the original paper that used this data. The raw data used in this report can be downloaded at the original [repo](https://nijianmo.github.io/amazon/index.html).\n",
    "\n",
    "Due to limited storage and computational capacity, I have elected to only conduct my analysis on the \"5-core\" version of Amazon Electronics reviews within the repository. The raw data is in json format, and therefore needs to be parsed and stored in a dataframe before any modeling or EDA can be done. For this process, I use the `parse()` and `getDF()` functions defined in the repository which is linked above. \n",
    "\n",
    "In case you are not familiar, the term \"5-core\" is in reference to dense subsets, and in this case it means that the data below has been filtered such that the remaining users and items have 5 reviews each. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Data Collection Code Overview\n",
    "\n",
    "Here, we begin the process by loading in our data. as stated above, The initial `parse()` and `getDF()` functions are borrowed from the link above as well. However, when initially trying to load and parse this data, I ran into serious memory issues that rendered my machine unable to successfully convert the data into a dataframe. Therefore, I elected to use the `orjson` library over the traditional `json`, which cut my import time dramatically. For reference to that repository, please head [here](https://github.com/ijl/orjson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Packages and Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import orjson\n",
    "\n",
    "# Loading in the data\n",
    "\n",
    "# Defining function that parses the json file\n",
    "def parse_orjson(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield orjson.loads(l)\n",
    "\n",
    "# Defining function to load the json data into a pandas dataframe\n",
    "def getDF_orjson(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse_orjson(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "# Retrieving data\n",
    "df = getDF_orjson('../../data/raw-data/Electronics.json.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that the data has been loaded, let's check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6739590, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the data shape\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6,739,590 reviews, which coincides with the count in the original repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zipping Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With that out of the way, we can zip up our data and continue on with the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/raw-data/electronics_reviews.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moving Forward**\n",
    "\n",
    "- Now that our data has been successfully collected and loaded, we can begin cleaning it in the [next](../data-cleaning/instructions.qmd) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include closing.qmd >}} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
